{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanishkbjain/TEI_HockeyPrediction/blob/main/notebooks/NN_log_rf_ada_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sorry, I did this in Colab for the GPU speedup while training, but it means the files aren't in the right place for you guys\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZB0MFLJoABIN",
        "outputId": "8e614352-af8d-4bc8-f039-28abfe0077a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZB0MFLJoABIN",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Boilerplate imports"
      ],
      "metadata": {
        "id": "ynwMuMwPACwo"
      },
      "id": "ynwMuMwPACwo"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c11e1fb8",
      "metadata": {
        "id": "c11e1fb8"
      },
      "outputs": [],
      "source": [
        "#allows drawing digrams in jupyeter notebooks\n",
        "%matplotlib inline\n",
        "#loading tensorboard\n",
        "%load_ext tensorboard\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#specific tensorflow libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import optimizers, metrics\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8ddf67cb",
      "metadata": {
        "id": "8ddf67cb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "276c70cf",
      "metadata": {
        "id": "276c70cf"
      },
      "outputs": [],
      "source": [
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "23f3f563",
      "metadata": {
        "id": "23f3f563"
      },
      "outputs": [],
      "source": [
        "from pandas.plotting import scatter_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "30b6b262",
      "metadata": {
        "id": "30b6b262"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Normalization and scaling"
      ],
      "metadata": {
        "id": "zwDyReuaAGAU"
      },
      "id": "zwDyReuaAGAU"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1948e2f2",
      "metadata": {
        "id": "1948e2f2"
      },
      "outputs": [],
      "source": [
        "def Train_Test_XY_normalize_PCA(TrainX, TrainY, TestX, PCA_n = None):\n",
        "    \n",
        "    # normalize data\n",
        "    scaler_new = StandardScaler()\n",
        "    scaler_new.fit(TrainX)\n",
        "    X_train_scale = scaler_new.transform(TrainX)\n",
        "    X_test_scale_list = [scaler_new.transform(TestX_now) for TestX_now in TestX]\n",
        "\n",
        "    print(f'X shape {X_train_scale.shape}')\n",
        "    \n",
        "    if PCA_n != None:\n",
        "        # dimension reduction\n",
        "        pca = PCA(n_components=PCA_n)\n",
        "        TrainX_PCA = pca.fit(X_train_scale)\n",
        "        TrainX_PCA = pca.transform(TrainX_PCA)\n",
        "        TestX_PCA_list = [pca.transform(TestX_now) for TestX_now in TestX]\n",
        "\n",
        "        print(f'X shape {TrainX_PCA.shape}')\n",
        "    \n",
        "        # normalize again\n",
        "        scaler_new = StandardScaler()\n",
        "        scaler_new.fit(TrainX_PCA)\n",
        "        X_train_scale = scaler_new.transform(TrainX_PCA)\n",
        "        X_test_scale = [scaler_new.transform(TestX_now) for TestX_now in TestX_PCA_list]\n",
        "\n",
        "\n",
        "        #Delete dis\n",
        "    return X_train_scale, 0, TrainY, 0, X_test_scale_list     \n",
        "    \n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_scale,TrainY,\n",
        "                                                       test_size=.0,\n",
        "                                                       shuffle=True,\n",
        "                                                       random_state=2020,\n",
        "                                                       stratify=TrainY)\n",
        "    \n",
        "    #return X_train, X_val, y_train, y_val, X_test_scale_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d2f024c6",
      "metadata": {
        "id": "d2f024c6"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras.backend as Kb\n",
        "\n",
        "# Write a custom loss function\n",
        "def custom_loss(y_true, y_pred):\n",
        "    binary_crossentropy = Kb.mean(Kb.binary_crossentropy(y_true, y_pred), axis = -1)\n",
        "    prob_constraint = Kb.square(Kb.sum(y_pred, axis = -1)\n",
        "                                - Kb.sum(y_true, axis = -1))\n",
        "\n",
        "    return(binary_crossentropy+prob_constraint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "9b429cbf",
      "metadata": {
        "id": "9b429cbf"
      },
      "outputs": [],
      "source": [
        "def NN_TF_model(structure, ipt_dim, learning_rate=0.01):\n",
        "    model=Sequential()\n",
        "\n",
        "    model.add(layers.Dense(structure[0], input_shape=(ipt_dim,), activation='relu'))\n",
        "    \n",
        "    for i in range(len(structure)-1):\n",
        "        model.add(layers.Dense(structure[i+1], activation='relu'))\n",
        "        #model.add(layers.Dropout(0.2))\n",
        "        \n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # opt = optimizers.SGD(learning_rate=0.01)\n",
        "    #opt = optimizers.Adam(learning_rate=0.01)\n",
        "    opt = optimizers.Nadam(learning_rate=0.01)\n",
        "\n",
        "    # model.compile(loss='mean_squared_error', optimizer=opt)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    # model.compile(loss=custom_loss, optimizer=opt)\n",
        "    # model.compile(loss='huber', optimizer=opt)\n",
        "    # model.compile(loss='binary_focal_crossentropy', optimizer=opt)\n",
        "    print(model.summary())\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60099a37",
      "metadata": {
        "id": "60099a37"
      },
      "source": [
        "# Models\n",
        "\n",
        "We can change what features we want to include: player? team? both?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "d674d4a9",
      "metadata": {
        "id": "d674d4a9",
        "outputId": "d2ba3084-d01d-4dc8-d2e9-9b5628d603f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Winner' 'F_home_assists' 'F_home_goals' 'F_home_pim' 'F_home_shots'\n",
            " 'F_home_blocked' 'F_home_hits' 'F_home_pm' 'D_home_assists'\n",
            " 'D_home_goals' 'D_home_pim' 'D_home_shots' 'D_home_blocked' 'D_home_hits'\n",
            " 'D_home_pm' 'G_home_GAA' 'F_away_assists' 'F_away_goals' 'F_away_pim'\n",
            " 'F_away_shots' 'F_away_blocked' 'F_away_hits' 'F_away_pm'\n",
            " 'D_away_assists' 'D_away_goals' 'D_away_pim' 'D_away_shots'\n",
            " 'D_away_blocked' 'D_away_hits' 'D_away_pm' 'G_away_GAA']\n"
          ]
        }
      ],
      "source": [
        "# see_column = np.array(['Rk', 'AvAge', 'GP', 'W', 'L', 'OL', 'PTS', 'PTS%',\n",
        "#        'GF', 'GA', 'SOW', 'SOL', 'SRS', 'SOS', 'GF/G', 'GA/G', 'PP', 'PPO',\n",
        "#        'PP%', 'PPA', 'PPOA', 'PK%', 'SH', 'SHA', 'PIM/G', 'oPIM/G', 'S', 'S%',\n",
        "#        'SA', 'SV%', 'SO', 'Hits', 'Hits/60', 'BkS', 'BkS/60', 'GvA', 'GvA/60',\n",
        "#        'TkA', 'TkA/60', 'ENG', 'MsS', '5v5 TOI/GP', 'SAT%', 'Playoffs%',\n",
        "#        'Playoffs', 'WonCup', 'TA/GA'])\n",
        "\n",
        "see_column = np.array(['PTS', 'W','L', 'GF', 'GA', 'SRS', \n",
        "                                  'SOS', 'PK%', 'S%', 'SV%', 'SAT%', \n",
        "                                  'MsS', 'TA/GA'])\n",
        "# see_column = np.array(['W', 'L', 'GA', 'SAT%', 'TA/GA'])\n",
        "\n",
        "see_column2 = np.array(['Winner',\n",
        "                       'F_home_assists', 'F_home_goals', 'F_home_pim', 'F_home_shots',\n",
        "                       'F_home_blocked', 'F_home_hits', 'F_home_pm', 'D_home_assists', 'D_home_goals',\n",
        "                       'D_home_pim', 'D_home_shots', 'D_home_blocked', 'D_home_hits',\n",
        "                       'D_home_pm', 'G_home_GAA', 'F_away_assists', 'F_away_goals', 'F_away_pim', 'F_away_shots',\n",
        "                       'F_away_blocked', 'F_away_hits', 'F_away_pm', 'D_away_assists', 'D_away_goals',\n",
        "                       'D_away_pim', 'D_away_shots', 'D_away_blocked', 'D_away_hits',\n",
        "                       'D_away_pm', 'G_away_GAA'])\n",
        "\n",
        "\n",
        "column_home = np.array([i+'_H' for i in see_column])\n",
        "column_away = np.array([i+'_A' for i in see_column])\n",
        "\n",
        "column_name = np.concatenate((column_home,column_away))\n",
        "\n",
        "column_name = np.concatenate((see_column2,column_name))\n",
        "#  column_name = np.concatenate((column_name,['class'])) # Winner is the class\n",
        "\n",
        "# ## only consider tm data\n",
        "# column_home = np.array([i+'_H' for i in see_column])\n",
        "# column_away = np.array([i+'_A' for i in see_column])\n",
        "# column_name = np.concatenate((column_home,column_away))\n",
        "# column_name = np.concatenate((['Winner'],column_name)) # Winner is the class\n",
        "\n",
        "## only consider players data\n",
        "column_name = see_column2\n",
        "\n",
        "print(column_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4284648c",
      "metadata": {
        "id": "4284648c"
      },
      "source": [
        "#### Train NN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "id": "51ce4fbf",
      "metadata": {
        "id": "51ce4fbf",
        "outputId": "527c864c-19a0-4568-a124-ab4adfcf0125",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Winner  F_home_assists  F_home_goals  F_home_pim  F_home_shots  \\\n",
              "11523       0        1.025894      0.812123    3.910935      7.668899   \n",
              "\n",
              "       F_home_blocked  F_home_hits  F_home_pm  D_home_assists  D_home_goals  \\\n",
              "11523        1.910511     5.675656  -0.008968        0.992456      0.240191   \n",
              "\n",
              "       ...  F_away_hits  F_away_pm  D_away_assists  D_away_goals  D_away_pim  \\\n",
              "11523  ...     5.335802  -0.047565          0.7556      0.174941    2.704355   \n",
              "\n",
              "       D_away_shots  D_away_blocked  D_away_hits  D_away_pm  G_away_GAA  \n",
              "11523      4.452401        4.337999     3.389377   0.218237    2.914226  \n",
              "\n",
              "[1 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f862ffba-7507-4949-a0df-5b86f93c871f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Winner</th>\n",
              "      <th>F_home_assists</th>\n",
              "      <th>F_home_goals</th>\n",
              "      <th>F_home_pim</th>\n",
              "      <th>F_home_shots</th>\n",
              "      <th>F_home_blocked</th>\n",
              "      <th>F_home_hits</th>\n",
              "      <th>F_home_pm</th>\n",
              "      <th>D_home_assists</th>\n",
              "      <th>D_home_goals</th>\n",
              "      <th>...</th>\n",
              "      <th>F_away_hits</th>\n",
              "      <th>F_away_pm</th>\n",
              "      <th>D_away_assists</th>\n",
              "      <th>D_away_goals</th>\n",
              "      <th>D_away_pim</th>\n",
              "      <th>D_away_shots</th>\n",
              "      <th>D_away_blocked</th>\n",
              "      <th>D_away_hits</th>\n",
              "      <th>D_away_pm</th>\n",
              "      <th>G_away_GAA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11523</th>\n",
              "      <td>0</td>\n",
              "      <td>1.025894</td>\n",
              "      <td>0.812123</td>\n",
              "      <td>3.910935</td>\n",
              "      <td>7.668899</td>\n",
              "      <td>1.910511</td>\n",
              "      <td>5.675656</td>\n",
              "      <td>-0.008968</td>\n",
              "      <td>0.992456</td>\n",
              "      <td>0.240191</td>\n",
              "      <td>...</td>\n",
              "      <td>5.335802</td>\n",
              "      <td>-0.047565</td>\n",
              "      <td>0.7556</td>\n",
              "      <td>0.174941</td>\n",
              "      <td>2.704355</td>\n",
              "      <td>4.452401</td>\n",
              "      <td>4.337999</td>\n",
              "      <td>3.389377</td>\n",
              "      <td>0.218237</td>\n",
              "      <td>2.914226</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows Ã— 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f862ffba-7507-4949-a0df-5b86f93c871f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f862ffba-7507-4949-a0df-5b86f93c871f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f862ffba-7507-4949-a0df-5b86f93c871f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ],
      "source": [
        "#You have to change these inputs back to what Chenyi had\n",
        "tm_players = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Erdos Institute Boot Camp/Erdos Institute Final Project - SKYLAB/Data/tm_player_stats_2005_2021.csv')\n",
        "playoff = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Erdos Institute Boot Camp/Erdos Institute Final Project - SKYLAB/Data/playoff_stats_2005_2021.csv')\n",
        "playoff_test = playoff[:-87]\n",
        "playoff_temp = playoff[1436:1509]\n",
        "#playoff_pred = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Erdos Institute Boot Camp/Erdos Institute Final Project - SKYLAB/Data/AllMatchups.csv')\n",
        "\n",
        "tm_players[column_name].sample(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create train and test sets.\n",
        "\n",
        "Additionally, come up with a set of every team playing every other team for prediction purposes X_pred"
      ],
      "metadata": {
        "id": "1xw2b7ZsBuVP"
      },
      "id": "1xw2b7ZsBuVP"
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "id": "68d4295a",
      "metadata": {
        "id": "68d4295a"
      },
      "outputs": [],
      "source": [
        "# Traindf_diff = pd.DataFrame(data = Traindf[column_home].to_numpy() \n",
        "#                                     - Traindf[column_away].to_numpy(), \n",
        "#                             columns = see_column)\n",
        "\n",
        "#Data from regular season: 2005-2021\n",
        "Traindf = tm_players[column_name]\n",
        "TrainX_array = Traindf[column_name[1:]].to_numpy()\n",
        "TrainY_array = Traindf[column_name[0]].to_numpy()\n",
        "\n",
        "#Data from playoffs: 2005-2020\n",
        "Testdf = playoff_test[column_name]\n",
        "TestX_array = Testdf[column_name[1:]].to_numpy()\n",
        "TestY_array = Testdf[column_name[0]].to_numpy()\n",
        "y_test = TestY_array\n",
        "\n",
        "#Data from playoffs: 2021\n",
        "tempdf = playoff_temp[column_name] \n",
        "tempX_array = tempdf[column_name[1:]].to_numpy()\n",
        "\n",
        "\n",
        "#Don't have y_pred because we don't know who won in 2021 yet\n",
        "#y_pred = Preddf[column_name[0]].to_numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "home_cols = np.array(['homeAbbrev', 'F_home_assists', 'F_home_goals', 'F_home_pim', 'F_home_shots',\n",
        "                       'F_home_blocked', 'F_home_hits', 'F_home_pm', 'D_home_assists', 'D_home_goals',\n",
        "                       'D_home_pim', 'D_home_shots', 'D_home_blocked', 'D_home_hits',\n",
        "                       'D_home_pm', 'G_home_GAA'])\n",
        "\n",
        "NN_cols = np.array(['F_home_assists', 'F_home_goals', 'F_home_pim', 'F_home_shots',\n",
        "                       'F_home_blocked', 'F_home_hits', 'F_home_pm', 'D_home_assists', 'D_home_goals',\n",
        "                       'D_home_pim', 'D_home_shots', 'D_home_blocked', 'D_home_hits',\n",
        "                       'D_home_pm', 'G_home_GAA'])"
      ],
      "metadata": {
        "id": "TRxZB6dxCioX"
      },
      "id": "TRxZB6dxCioX",
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TeamList = ['COL', 'NSH', 'MIN', 'STL', 'CGY', 'DAL', 'EDM', 'LAK', 'FLA', 'WSH', 'TOR', 'TBL', 'CAR', 'BOS', 'NYR', 'PIT']\n",
        "\n",
        "#This is the data from the most recent game we have data available for\n",
        "dfs = [(playoff_temp[home_cols].loc[(playoff_temp.homeAbbrev == team)].tail(1)) for team in TeamList]\n",
        "TeamAverages = pd.concat(dfs, ignore_index = True)\n",
        "TeamAverages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "KFWiYZECB1MV",
        "outputId": "1b651feb-d765-4ab2-9a88-b98fb4ca04de"
      },
      "id": "KFWiYZECB1MV",
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   homeAbbrev  F_home_assists  F_home_goals  F_home_pim  F_home_shots  \\\n",
              "0         COL        1.354877      0.897446    1.693630      7.865989   \n",
              "1         NSH        1.147841      0.864018    2.642927      6.676903   \n",
              "2         MIN        1.454759      0.871291    3.463298      8.113439   \n",
              "3         STL        1.610160      1.099073    1.337461      7.288217   \n",
              "4         CGY        1.270271      1.002407    1.804618      8.304612   \n",
              "5         DAL        0.977506      0.709077    1.346791      6.725738   \n",
              "6         EDM        1.270053      0.930354    2.022099      7.384278   \n",
              "7         LAK        0.951035      0.873424    1.903912      8.545825   \n",
              "8         FLA        1.644462      1.140087    2.132880      8.435701   \n",
              "9         WSH        1.238918      0.859159    1.728240      7.078066   \n",
              "10        TOR        1.316698      0.998464    1.796410      8.700371   \n",
              "11        TBL        1.218523      0.954218    2.040475      7.420484   \n",
              "12        CAR        1.297849      0.945376    1.815331      7.611912   \n",
              "13        BOS        1.047789      0.776380    2.242070      8.409460   \n",
              "14        NYR        1.059499      0.769645    1.540431      6.982735   \n",
              "15        PIT        1.290771      1.020564    1.209887      8.642701   \n",
              "\n",
              "    F_home_blocked  F_home_hits  F_home_pm  D_home_assists  D_home_goals  \\\n",
              "0         2.007970     4.694978   0.483299        1.012747      0.377212   \n",
              "1         2.109020     7.565427  -0.011657        0.869903      0.188685   \n",
              "2         1.710650     7.158114   0.428524        0.802816      0.241591   \n",
              "3         1.554599     3.899510   0.317211        0.927065      0.247134   \n",
              "4         1.407937     5.228458   0.708209        1.059640      0.248739   \n",
              "5         2.068485     5.346605  -0.454931        0.789127      0.180640   \n",
              "6         1.295797     6.416885   0.395703        0.863851      0.225268   \n",
              "7         1.639262     4.187482   0.013353        0.674483      0.104678   \n",
              "8         1.585193     4.890510   0.854797        0.920505      0.306456   \n",
              "9         1.956336     5.427952  -0.045069        0.835282      0.301264   \n",
              "10        1.834604     4.528443   0.111125        1.058657      0.193572   \n",
              "11        1.583201     5.424256  -0.340505        0.832702      0.211923   \n",
              "12        1.221205     5.118141   0.659153        1.016184      0.278281   \n",
              "13        1.651912     7.984762  -0.225283        0.613150      0.211399   \n",
              "14        1.897344     5.403891   0.240291        0.700101      0.235790   \n",
              "15        1.821981     4.321032   0.320898        0.920525      0.188419   \n",
              "\n",
              "    D_home_pim  D_home_shots  D_home_blocked  D_home_hits  D_home_pm  \\\n",
              "0     1.725935      4.977005        3.666825     4.881980   0.618378   \n",
              "1     3.097599      4.577687        4.089691     5.819146  -0.028379   \n",
              "2     1.353866      3.969292        4.108469     3.713037   0.903035   \n",
              "3     1.522250      4.026448        3.868756     3.642786   0.276109   \n",
              "4     1.857672      5.465385        3.756104     4.240612   0.683349   \n",
              "5     1.113347      4.233014        3.808293     3.781154  -0.309382   \n",
              "6     1.137328      5.099719        4.318837     4.659886  -0.601595   \n",
              "7     1.027555      4.446804        4.229748     4.207890   0.205611   \n",
              "8     1.981336      5.470553        4.065651     6.073890   0.694921   \n",
              "9     1.486159      4.583104        4.432774     4.906950   0.270857   \n",
              "10    1.824681      4.575004        3.692434     5.501248   0.259145   \n",
              "11    1.746099      4.481311        4.361286     5.699698   0.437693   \n",
              "12    1.978206      5.807338        3.483390     3.162029   0.720928   \n",
              "13    2.662175      4.673748        3.824459     5.003442  -0.096109   \n",
              "14    1.540027      3.887425        4.870492     4.548692  -0.208205   \n",
              "15    1.819158      4.724365        3.994383     4.644278   0.266195   \n",
              "\n",
              "    G_home_GAA  \n",
              "0     3.079092  \n",
              "1     3.179254  \n",
              "2     2.904200  \n",
              "3     2.846504  \n",
              "4     2.224100  \n",
              "5     2.526200  \n",
              "6     2.712707  \n",
              "7     2.591300  \n",
              "8     3.548598  \n",
              "9     3.062784  \n",
              "10    3.397821  \n",
              "11    4.881898  \n",
              "12    3.250879  \n",
              "13    2.409800  \n",
              "14    2.035025  \n",
              "15    2.402009  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c7f01b2-f8b8-4115-b82f-53531d4f8aa3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>homeAbbrev</th>\n",
              "      <th>F_home_assists</th>\n",
              "      <th>F_home_goals</th>\n",
              "      <th>F_home_pim</th>\n",
              "      <th>F_home_shots</th>\n",
              "      <th>F_home_blocked</th>\n",
              "      <th>F_home_hits</th>\n",
              "      <th>F_home_pm</th>\n",
              "      <th>D_home_assists</th>\n",
              "      <th>D_home_goals</th>\n",
              "      <th>D_home_pim</th>\n",
              "      <th>D_home_shots</th>\n",
              "      <th>D_home_blocked</th>\n",
              "      <th>D_home_hits</th>\n",
              "      <th>D_home_pm</th>\n",
              "      <th>G_home_GAA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>COL</td>\n",
              "      <td>1.354877</td>\n",
              "      <td>0.897446</td>\n",
              "      <td>1.693630</td>\n",
              "      <td>7.865989</td>\n",
              "      <td>2.007970</td>\n",
              "      <td>4.694978</td>\n",
              "      <td>0.483299</td>\n",
              "      <td>1.012747</td>\n",
              "      <td>0.377212</td>\n",
              "      <td>1.725935</td>\n",
              "      <td>4.977005</td>\n",
              "      <td>3.666825</td>\n",
              "      <td>4.881980</td>\n",
              "      <td>0.618378</td>\n",
              "      <td>3.079092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NSH</td>\n",
              "      <td>1.147841</td>\n",
              "      <td>0.864018</td>\n",
              "      <td>2.642927</td>\n",
              "      <td>6.676903</td>\n",
              "      <td>2.109020</td>\n",
              "      <td>7.565427</td>\n",
              "      <td>-0.011657</td>\n",
              "      <td>0.869903</td>\n",
              "      <td>0.188685</td>\n",
              "      <td>3.097599</td>\n",
              "      <td>4.577687</td>\n",
              "      <td>4.089691</td>\n",
              "      <td>5.819146</td>\n",
              "      <td>-0.028379</td>\n",
              "      <td>3.179254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MIN</td>\n",
              "      <td>1.454759</td>\n",
              "      <td>0.871291</td>\n",
              "      <td>3.463298</td>\n",
              "      <td>8.113439</td>\n",
              "      <td>1.710650</td>\n",
              "      <td>7.158114</td>\n",
              "      <td>0.428524</td>\n",
              "      <td>0.802816</td>\n",
              "      <td>0.241591</td>\n",
              "      <td>1.353866</td>\n",
              "      <td>3.969292</td>\n",
              "      <td>4.108469</td>\n",
              "      <td>3.713037</td>\n",
              "      <td>0.903035</td>\n",
              "      <td>2.904200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>STL</td>\n",
              "      <td>1.610160</td>\n",
              "      <td>1.099073</td>\n",
              "      <td>1.337461</td>\n",
              "      <td>7.288217</td>\n",
              "      <td>1.554599</td>\n",
              "      <td>3.899510</td>\n",
              "      <td>0.317211</td>\n",
              "      <td>0.927065</td>\n",
              "      <td>0.247134</td>\n",
              "      <td>1.522250</td>\n",
              "      <td>4.026448</td>\n",
              "      <td>3.868756</td>\n",
              "      <td>3.642786</td>\n",
              "      <td>0.276109</td>\n",
              "      <td>2.846504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CGY</td>\n",
              "      <td>1.270271</td>\n",
              "      <td>1.002407</td>\n",
              "      <td>1.804618</td>\n",
              "      <td>8.304612</td>\n",
              "      <td>1.407937</td>\n",
              "      <td>5.228458</td>\n",
              "      <td>0.708209</td>\n",
              "      <td>1.059640</td>\n",
              "      <td>0.248739</td>\n",
              "      <td>1.857672</td>\n",
              "      <td>5.465385</td>\n",
              "      <td>3.756104</td>\n",
              "      <td>4.240612</td>\n",
              "      <td>0.683349</td>\n",
              "      <td>2.224100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>DAL</td>\n",
              "      <td>0.977506</td>\n",
              "      <td>0.709077</td>\n",
              "      <td>1.346791</td>\n",
              "      <td>6.725738</td>\n",
              "      <td>2.068485</td>\n",
              "      <td>5.346605</td>\n",
              "      <td>-0.454931</td>\n",
              "      <td>0.789127</td>\n",
              "      <td>0.180640</td>\n",
              "      <td>1.113347</td>\n",
              "      <td>4.233014</td>\n",
              "      <td>3.808293</td>\n",
              "      <td>3.781154</td>\n",
              "      <td>-0.309382</td>\n",
              "      <td>2.526200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>EDM</td>\n",
              "      <td>1.270053</td>\n",
              "      <td>0.930354</td>\n",
              "      <td>2.022099</td>\n",
              "      <td>7.384278</td>\n",
              "      <td>1.295797</td>\n",
              "      <td>6.416885</td>\n",
              "      <td>0.395703</td>\n",
              "      <td>0.863851</td>\n",
              "      <td>0.225268</td>\n",
              "      <td>1.137328</td>\n",
              "      <td>5.099719</td>\n",
              "      <td>4.318837</td>\n",
              "      <td>4.659886</td>\n",
              "      <td>-0.601595</td>\n",
              "      <td>2.712707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LAK</td>\n",
              "      <td>0.951035</td>\n",
              "      <td>0.873424</td>\n",
              "      <td>1.903912</td>\n",
              "      <td>8.545825</td>\n",
              "      <td>1.639262</td>\n",
              "      <td>4.187482</td>\n",
              "      <td>0.013353</td>\n",
              "      <td>0.674483</td>\n",
              "      <td>0.104678</td>\n",
              "      <td>1.027555</td>\n",
              "      <td>4.446804</td>\n",
              "      <td>4.229748</td>\n",
              "      <td>4.207890</td>\n",
              "      <td>0.205611</td>\n",
              "      <td>2.591300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>FLA</td>\n",
              "      <td>1.644462</td>\n",
              "      <td>1.140087</td>\n",
              "      <td>2.132880</td>\n",
              "      <td>8.435701</td>\n",
              "      <td>1.585193</td>\n",
              "      <td>4.890510</td>\n",
              "      <td>0.854797</td>\n",
              "      <td>0.920505</td>\n",
              "      <td>0.306456</td>\n",
              "      <td>1.981336</td>\n",
              "      <td>5.470553</td>\n",
              "      <td>4.065651</td>\n",
              "      <td>6.073890</td>\n",
              "      <td>0.694921</td>\n",
              "      <td>3.548598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>WSH</td>\n",
              "      <td>1.238918</td>\n",
              "      <td>0.859159</td>\n",
              "      <td>1.728240</td>\n",
              "      <td>7.078066</td>\n",
              "      <td>1.956336</td>\n",
              "      <td>5.427952</td>\n",
              "      <td>-0.045069</td>\n",
              "      <td>0.835282</td>\n",
              "      <td>0.301264</td>\n",
              "      <td>1.486159</td>\n",
              "      <td>4.583104</td>\n",
              "      <td>4.432774</td>\n",
              "      <td>4.906950</td>\n",
              "      <td>0.270857</td>\n",
              "      <td>3.062784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>TOR</td>\n",
              "      <td>1.316698</td>\n",
              "      <td>0.998464</td>\n",
              "      <td>1.796410</td>\n",
              "      <td>8.700371</td>\n",
              "      <td>1.834604</td>\n",
              "      <td>4.528443</td>\n",
              "      <td>0.111125</td>\n",
              "      <td>1.058657</td>\n",
              "      <td>0.193572</td>\n",
              "      <td>1.824681</td>\n",
              "      <td>4.575004</td>\n",
              "      <td>3.692434</td>\n",
              "      <td>5.501248</td>\n",
              "      <td>0.259145</td>\n",
              "      <td>3.397821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>TBL</td>\n",
              "      <td>1.218523</td>\n",
              "      <td>0.954218</td>\n",
              "      <td>2.040475</td>\n",
              "      <td>7.420484</td>\n",
              "      <td>1.583201</td>\n",
              "      <td>5.424256</td>\n",
              "      <td>-0.340505</td>\n",
              "      <td>0.832702</td>\n",
              "      <td>0.211923</td>\n",
              "      <td>1.746099</td>\n",
              "      <td>4.481311</td>\n",
              "      <td>4.361286</td>\n",
              "      <td>5.699698</td>\n",
              "      <td>0.437693</td>\n",
              "      <td>4.881898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>CAR</td>\n",
              "      <td>1.297849</td>\n",
              "      <td>0.945376</td>\n",
              "      <td>1.815331</td>\n",
              "      <td>7.611912</td>\n",
              "      <td>1.221205</td>\n",
              "      <td>5.118141</td>\n",
              "      <td>0.659153</td>\n",
              "      <td>1.016184</td>\n",
              "      <td>0.278281</td>\n",
              "      <td>1.978206</td>\n",
              "      <td>5.807338</td>\n",
              "      <td>3.483390</td>\n",
              "      <td>3.162029</td>\n",
              "      <td>0.720928</td>\n",
              "      <td>3.250879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>BOS</td>\n",
              "      <td>1.047789</td>\n",
              "      <td>0.776380</td>\n",
              "      <td>2.242070</td>\n",
              "      <td>8.409460</td>\n",
              "      <td>1.651912</td>\n",
              "      <td>7.984762</td>\n",
              "      <td>-0.225283</td>\n",
              "      <td>0.613150</td>\n",
              "      <td>0.211399</td>\n",
              "      <td>2.662175</td>\n",
              "      <td>4.673748</td>\n",
              "      <td>3.824459</td>\n",
              "      <td>5.003442</td>\n",
              "      <td>-0.096109</td>\n",
              "      <td>2.409800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>NYR</td>\n",
              "      <td>1.059499</td>\n",
              "      <td>0.769645</td>\n",
              "      <td>1.540431</td>\n",
              "      <td>6.982735</td>\n",
              "      <td>1.897344</td>\n",
              "      <td>5.403891</td>\n",
              "      <td>0.240291</td>\n",
              "      <td>0.700101</td>\n",
              "      <td>0.235790</td>\n",
              "      <td>1.540027</td>\n",
              "      <td>3.887425</td>\n",
              "      <td>4.870492</td>\n",
              "      <td>4.548692</td>\n",
              "      <td>-0.208205</td>\n",
              "      <td>2.035025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>PIT</td>\n",
              "      <td>1.290771</td>\n",
              "      <td>1.020564</td>\n",
              "      <td>1.209887</td>\n",
              "      <td>8.642701</td>\n",
              "      <td>1.821981</td>\n",
              "      <td>4.321032</td>\n",
              "      <td>0.320898</td>\n",
              "      <td>0.920525</td>\n",
              "      <td>0.188419</td>\n",
              "      <td>1.819158</td>\n",
              "      <td>4.724365</td>\n",
              "      <td>3.994383</td>\n",
              "      <td>4.644278</td>\n",
              "      <td>0.266195</td>\n",
              "      <td>2.402009</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c7f01b2-f8b8-4115-b82f-53531d4f8aa3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6c7f01b2-f8b8-4115-b82f-53531d4f8aa3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6c7f01b2-f8b8-4115-b82f-53531d4f8aa3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfs_home = [(TeamAverages[NN_cols].loc[i].to_numpy()) for i in range(len(TeamAverages)) for j in range(len(TeamAverages))]\n",
        "dfs_away = [(TeamAverages[NN_cols].loc[j].to_numpy()) for i in range(len(TeamAverages)) for j in range(len(TeamAverages))]\n",
        "                                                                         \n",
        "new_home = np.vstack(dfs_home)\n",
        "new_away = np.vstack(dfs_away)\n",
        "X_pred = np.hstack((new_home, new_away))\n",
        "#This has 16*16 columns in it: one for every possible matchup between teams\n",
        "X_pred\n",
        "\n",
        "PredX_array = X_pred"
      ],
      "metadata": {
        "id": "lYDJKfSXB2z_"
      },
      "id": "lYDJKfSXB2z_",
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "id": "fe19763c",
      "metadata": {
        "id": "fe19763c",
        "outputId": "2a09a584-9bf9-4cc6-d566-0e2c5d439fa8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape (20050, 30)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, y_train, y_val, [X_pred, X_test, X_temp] = Train_Test_XY_normalize_PCA(TrainX_array, \n",
        "                                                                    TrainY_array, \n",
        "                                                                   # TestX_array)                                                                     \n",
        "                                                                     [PredX_array, TestX_array, tempX_array])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA Doesn't help. Skip it"
      ],
      "metadata": {
        "id": "UHCCsxRbf7N5"
      },
      "id": "UHCCsxRbf7N5"
    },
    {
      "cell_type": "code",
      "source": [
        "#pca = PCA(n_components=0.9)\n",
        "#pca.fit(X_train)\n",
        "#X_train = pca.transform(X_train)\n",
        "#X_val = pca.transform(X_val)\n",
        "#X_test = pca.transform(X_test)\n",
        "#X_pred = pca.transform(X_pred)\n",
        "#X_temp = pca.transform(X_temp)"
      ],
      "metadata": {
        "id": "p_fr6s-SdnX8"
      },
      "id": "p_fr6s-SdnX8",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Neural Network model"
      ],
      "metadata": {
        "id": "f-v0_XOHDxS7"
      },
      "id": "f-v0_XOHDxS7"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "f6d38592",
      "metadata": {
        "scrolled": true,
        "id": "f6d38592",
        "outputId": "95bcc5fe-becb-4e19-859d-92435e04f068",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_15 (Dense)            (None, 30)                930       \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 30)                930       \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,891\n",
            "Trainable params: 1,891\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "161/161 [==============================] - 2s 5ms/step - loss: 0.6582 - accuracy: 0.6076 - val_loss: 0.6523 - val_accuracy: 0.6100\n",
            "Epoch 2/200\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.6477 - accuracy: 0.6182 - val_loss: 0.6531 - val_accuracy: 0.6172\n",
            "Epoch 3/200\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.6230 - val_loss: 0.6521 - val_accuracy: 0.6035\n",
            "Epoch 4/200\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.6443 - accuracy: 0.6229 - val_loss: 0.6566 - val_accuracy: 0.6142\n",
            "Epoch 5/200\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.6431 - accuracy: 0.6231 - val_loss: 0.6677 - val_accuracy: 0.6045\n",
            "Epoch 6/200\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.6420 - accuracy: 0.6262 - val_loss: 0.6559 - val_accuracy: 0.6062\n",
            "Epoch 7/200\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.6410 - accuracy: 0.6269 - val_loss: 0.6609 - val_accuracy: 0.6160\n",
            "Epoch 8/200\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.6400 - accuracy: 0.6310 - val_loss: 0.6625 - val_accuracy: 0.6012\n",
            "Epoch 9/200\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.6382 - accuracy: 0.6327 - val_loss: 0.6732 - val_accuracy: 0.5960\n",
            "Epoch 10/200\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.6379 - accuracy: 0.6287 - val_loss: 0.6626 - val_accuracy: 0.6100\n",
            "Epoch 11/200\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.6353 - accuracy: 0.6353 - val_loss: 0.6726 - val_accuracy: 0.6075\n",
            "Epoch 12/200\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.6332 - accuracy: 0.6347 - val_loss: 0.6686 - val_accuracy: 0.6062\n",
            "Epoch 13/200\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.6319 - accuracy: 0.6355 - val_loss: 0.6761 - val_accuracy: 0.6040\n",
            "Epoch 14/200\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.6296 - accuracy: 0.6379 - val_loss: 0.6712 - val_accuracy: 0.6055\n",
            "Epoch 15/200\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.6267 - accuracy: 0.6409 - val_loss: 0.6768 - val_accuracy: 0.5970\n",
            "Epoch 16/200\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.6237 - accuracy: 0.6419 - val_loss: 0.6829 - val_accuracy: 0.6017\n",
            "Epoch 17/200\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.6222 - accuracy: 0.6451 - val_loss: 0.7005 - val_accuracy: 0.5830\n",
            "Epoch 18/200\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.6204 - accuracy: 0.6484 - val_loss: 0.7426 - val_accuracy: 0.5888\n",
            "Epoch 19/200\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.6176 - accuracy: 0.6506 - val_loss: 0.7284 - val_accuracy: 0.5880\n",
            "Epoch 20/200\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.6147 - accuracy: 0.6506 - val_loss: 0.7133 - val_accuracy: 0.5980\n",
            "Epoch 21/200\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.6117 - accuracy: 0.6592 - val_loss: 0.7269 - val_accuracy: 0.5965\n",
            "Epoch 22/200\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.6108 - accuracy: 0.6557 - val_loss: 0.7226 - val_accuracy: 0.5813\n",
            "Epoch 23/200\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.6062 - accuracy: 0.6647 - val_loss: 0.7226 - val_accuracy: 0.5908\n",
            "Epoch 24/200\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.6056 - accuracy: 0.6613 - val_loss: 0.7232 - val_accuracy: 0.5858\n",
            "Epoch 25/200\n",
            "161/161 [==============================] - 1s 6ms/step - loss: 0.6028 - accuracy: 0.6610 - val_loss: 0.7997 - val_accuracy: 0.5918\n",
            "Epoch 26/200\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.5994 - accuracy: 0.6634 - val_loss: 0.7913 - val_accuracy: 0.5883\n",
            "Epoch 27/200\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.5966 - accuracy: 0.6671 - val_loss: 0.7639 - val_accuracy: 0.5693\n",
            "Epoch 28/200\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.6682 - val_loss: 0.7878 - val_accuracy: 0.5756\n",
            "Epoch 29/200\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.5912 - accuracy: 0.6697 - val_loss: 0.7865 - val_accuracy: 0.5791\n",
            "Epoch 30/200\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.5898 - accuracy: 0.6737 - val_loss: 0.7801 - val_accuracy: 0.5701\n",
            "Epoch 31/200\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.5848 - accuracy: 0.6761 - val_loss: 0.8003 - val_accuracy: 0.5773\n",
            "Epoch 32/200\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.5839 - accuracy: 0.6759 - val_loss: 0.8125 - val_accuracy: 0.5663\n",
            "Epoch 33/200\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.5838 - accuracy: 0.6751 - val_loss: 0.7864 - val_accuracy: 0.5761\n",
            "Epoch 34/200\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.6764 - val_loss: 0.8170 - val_accuracy: 0.5778\n",
            "Epoch 35/200\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.5796 - accuracy: 0.6797 - val_loss: 0.7888 - val_accuracy: 0.5618\n",
            "Epoch 36/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5763 - accuracy: 0.6808 - val_loss: 0.8454 - val_accuracy: 0.5643\n",
            "Epoch 37/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5746 - accuracy: 0.6850 - val_loss: 0.7960 - val_accuracy: 0.5666\n",
            "Epoch 38/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.6847 - val_loss: 0.8422 - val_accuracy: 0.5723\n",
            "Epoch 39/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5707 - accuracy: 0.6883 - val_loss: 0.8383 - val_accuracy: 0.5611\n",
            "Epoch 40/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.6882 - val_loss: 0.8335 - val_accuracy: 0.5633\n",
            "Epoch 41/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.6865 - val_loss: 0.8769 - val_accuracy: 0.5671\n",
            "Epoch 42/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.6858 - val_loss: 0.8434 - val_accuracy: 0.5673\n",
            "Epoch 43/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.6924 - val_loss: 0.8350 - val_accuracy: 0.5668\n",
            "Epoch 44/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.6918 - val_loss: 0.8943 - val_accuracy: 0.5641\n",
            "Epoch 45/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.6909 - val_loss: 0.8766 - val_accuracy: 0.5549\n",
            "Epoch 46/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.6906 - val_loss: 0.9081 - val_accuracy: 0.5658\n",
            "Epoch 47/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.6959 - val_loss: 0.8496 - val_accuracy: 0.5648\n",
            "Epoch 48/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.6952 - val_loss: 0.9522 - val_accuracy: 0.5576\n",
            "Epoch 49/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.6950 - val_loss: 0.9418 - val_accuracy: 0.5691\n",
            "Epoch 50/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.6934 - val_loss: 0.9129 - val_accuracy: 0.5569\n",
            "Epoch 51/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.6986 - val_loss: 0.9882 - val_accuracy: 0.5648\n",
            "Epoch 52/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.6976 - val_loss: 0.9616 - val_accuracy: 0.5534\n",
            "Epoch 53/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.6969 - val_loss: 0.9610 - val_accuracy: 0.5758\n",
            "Epoch 54/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5542 - accuracy: 0.6964 - val_loss: 0.9599 - val_accuracy: 0.5616\n",
            "Epoch 55/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5517 - accuracy: 0.6948 - val_loss: 0.9911 - val_accuracy: 0.5589\n",
            "Epoch 56/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.6968 - val_loss: 0.9407 - val_accuracy: 0.5633\n",
            "Epoch 57/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.6988 - val_loss: 1.0423 - val_accuracy: 0.5504\n",
            "Epoch 58/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.6984 - val_loss: 1.0513 - val_accuracy: 0.5606\n",
            "Epoch 59/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.6987 - val_loss: 0.9565 - val_accuracy: 0.5633\n",
            "Epoch 60/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7012 - val_loss: 0.9651 - val_accuracy: 0.5648\n",
            "Epoch 61/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7013 - val_loss: 0.9952 - val_accuracy: 0.5591\n",
            "Epoch 62/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.7027 - val_loss: 1.0500 - val_accuracy: 0.5626\n",
            "Epoch 63/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.6996 - val_loss: 1.0844 - val_accuracy: 0.5511\n",
            "Epoch 64/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.6996 - val_loss: 1.1103 - val_accuracy: 0.5643\n",
            "Epoch 65/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7016 - val_loss: 1.0525 - val_accuracy: 0.5544\n",
            "Epoch 66/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7020 - val_loss: 1.1190 - val_accuracy: 0.5628\n",
            "Epoch 67/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7064 - val_loss: 1.1396 - val_accuracy: 0.5698\n",
            "Epoch 68/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7042 - val_loss: 0.9969 - val_accuracy: 0.5576\n",
            "Epoch 69/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7034 - val_loss: 1.0215 - val_accuracy: 0.5676\n",
            "Epoch 70/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7039 - val_loss: 1.1009 - val_accuracy: 0.5626\n",
            "Epoch 71/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7026 - val_loss: 1.1958 - val_accuracy: 0.5656\n",
            "Epoch 72/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7039 - val_loss: 1.0793 - val_accuracy: 0.5519\n",
            "Epoch 73/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7052 - val_loss: 1.1866 - val_accuracy: 0.5603\n",
            "Epoch 74/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7031 - val_loss: 1.0755 - val_accuracy: 0.5586\n",
            "Epoch 75/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7031 - val_loss: 1.1580 - val_accuracy: 0.5479\n",
            "Epoch 76/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7094 - val_loss: 1.1353 - val_accuracy: 0.5584\n",
            "Epoch 77/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7079 - val_loss: 1.1747 - val_accuracy: 0.5519\n",
            "Epoch 78/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7056 - val_loss: 1.2499 - val_accuracy: 0.5666\n",
            "Epoch 79/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7026 - val_loss: 1.2121 - val_accuracy: 0.5581\n",
            "Epoch 80/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7050 - val_loss: 1.1681 - val_accuracy: 0.5569\n",
            "Epoch 81/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7063 - val_loss: 1.2044 - val_accuracy: 0.5636\n",
            "Epoch 82/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7097 - val_loss: 1.2355 - val_accuracy: 0.5549\n",
            "Epoch 83/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7069 - val_loss: 1.2417 - val_accuracy: 0.5631\n",
            "Epoch 84/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7118 - val_loss: 1.2154 - val_accuracy: 0.5521\n",
            "Epoch 85/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7044 - val_loss: 1.2163 - val_accuracy: 0.5623\n",
            "Epoch 86/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7075 - val_loss: 1.2137 - val_accuracy: 0.5611\n",
            "Epoch 87/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7105 - val_loss: 1.2284 - val_accuracy: 0.5678\n",
            "Epoch 88/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7084 - val_loss: 1.2298 - val_accuracy: 0.5589\n",
            "Epoch 89/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7085 - val_loss: 1.2570 - val_accuracy: 0.5576\n",
            "Epoch 90/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7071 - val_loss: 1.2493 - val_accuracy: 0.5623\n",
            "Epoch 91/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7095 - val_loss: 1.2605 - val_accuracy: 0.5589\n",
            "Epoch 92/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7094 - val_loss: 1.3813 - val_accuracy: 0.5696\n",
            "Epoch 93/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7119 - val_loss: 1.3219 - val_accuracy: 0.5648\n",
            "Epoch 94/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7104 - val_loss: 1.1684 - val_accuracy: 0.5601\n",
            "Epoch 95/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7115 - val_loss: 1.2530 - val_accuracy: 0.5658\n",
            "Epoch 96/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7101 - val_loss: 1.4065 - val_accuracy: 0.5574\n",
            "Epoch 97/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7097 - val_loss: 1.2518 - val_accuracy: 0.5646\n",
            "Epoch 98/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7145 - val_loss: 1.2435 - val_accuracy: 0.5688\n",
            "Epoch 99/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7134 - val_loss: 1.3406 - val_accuracy: 0.5534\n",
            "Epoch 100/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7129 - val_loss: 1.2464 - val_accuracy: 0.5576\n",
            "Epoch 101/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7133 - val_loss: 1.3363 - val_accuracy: 0.5648\n",
            "Epoch 102/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7105 - val_loss: 1.3373 - val_accuracy: 0.5671\n",
            "Epoch 103/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7127 - val_loss: 1.5522 - val_accuracy: 0.5716\n",
            "Epoch 104/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7140 - val_loss: 1.2881 - val_accuracy: 0.5613\n",
            "Epoch 105/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7128 - val_loss: 1.3697 - val_accuracy: 0.5651\n",
            "Epoch 106/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.7138 - val_loss: 1.3259 - val_accuracy: 0.5641\n",
            "Epoch 107/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7147 - val_loss: 1.3206 - val_accuracy: 0.5618\n",
            "Epoch 108/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7117 - val_loss: 1.3139 - val_accuracy: 0.5633\n",
            "Epoch 109/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7135 - val_loss: 1.3477 - val_accuracy: 0.5608\n",
            "Epoch 110/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7123 - val_loss: 1.3793 - val_accuracy: 0.5661\n",
            "Epoch 111/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7135 - val_loss: 1.3315 - val_accuracy: 0.5586\n",
            "Epoch 112/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7169 - val_loss: 1.4579 - val_accuracy: 0.5623\n",
            "Epoch 113/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7160 - val_loss: 1.4939 - val_accuracy: 0.5628\n",
            "Epoch 114/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7150 - val_loss: 1.4381 - val_accuracy: 0.5606\n",
            "Epoch 115/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7152 - val_loss: 1.4151 - val_accuracy: 0.5623\n",
            "Epoch 116/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7150 - val_loss: 1.3826 - val_accuracy: 0.5586\n",
            "Epoch 117/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7158 - val_loss: 1.3856 - val_accuracy: 0.5698\n",
            "Epoch 118/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7166 - val_loss: 1.3760 - val_accuracy: 0.5631\n",
            "Epoch 119/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7158 - val_loss: 1.4833 - val_accuracy: 0.5663\n",
            "Epoch 120/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7168 - val_loss: 1.4445 - val_accuracy: 0.5658\n",
            "Epoch 121/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7160 - val_loss: 1.4411 - val_accuracy: 0.5748\n",
            "Epoch 122/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7188 - val_loss: 1.4423 - val_accuracy: 0.5688\n",
            "Epoch 123/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7129 - val_loss: 1.4630 - val_accuracy: 0.5591\n",
            "Epoch 124/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7176 - val_loss: 1.5094 - val_accuracy: 0.5678\n",
            "Epoch 125/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7142 - val_loss: 1.3745 - val_accuracy: 0.5603\n",
            "Epoch 126/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7160 - val_loss: 1.4661 - val_accuracy: 0.5599\n",
            "Epoch 127/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7160 - val_loss: 1.5017 - val_accuracy: 0.5608\n",
            "Epoch 128/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7185 - val_loss: 1.4910 - val_accuracy: 0.5606\n",
            "Epoch 129/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7158 - val_loss: 1.4851 - val_accuracy: 0.5616\n",
            "Epoch 130/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7170 - val_loss: 1.4238 - val_accuracy: 0.5653\n",
            "Epoch 131/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7163 - val_loss: 1.5822 - val_accuracy: 0.5616\n",
            "Epoch 132/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7190 - val_loss: 1.5763 - val_accuracy: 0.5661\n",
            "Epoch 133/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7153 - val_loss: 1.5825 - val_accuracy: 0.5641\n",
            "Epoch 134/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7186 - val_loss: 1.4475 - val_accuracy: 0.5524\n",
            "Epoch 135/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7168 - val_loss: 1.5162 - val_accuracy: 0.5581\n",
            "Epoch 136/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7168 - val_loss: 1.5715 - val_accuracy: 0.5586\n",
            "Epoch 137/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7180 - val_loss: 1.5318 - val_accuracy: 0.5608\n",
            "Epoch 138/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7179 - val_loss: 1.5279 - val_accuracy: 0.5656\n",
            "Epoch 139/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7206 - val_loss: 1.5351 - val_accuracy: 0.5596\n",
            "Epoch 140/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7163 - val_loss: 1.4090 - val_accuracy: 0.5621\n",
            "Epoch 141/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7175 - val_loss: 1.6243 - val_accuracy: 0.5556\n",
            "Epoch 142/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7185 - val_loss: 1.5220 - val_accuracy: 0.5586\n",
            "Epoch 143/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7188 - val_loss: 1.7043 - val_accuracy: 0.5601\n",
            "Epoch 144/200\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.5128 - accuracy: 0.7170 - val_loss: 1.6220 - val_accuracy: 0.5708\n",
            "Epoch 145/200\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.5118 - accuracy: 0.7191 - val_loss: 1.5528 - val_accuracy: 0.5668\n",
            "Epoch 146/200\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.5142 - accuracy: 0.7196 - val_loss: 1.5920 - val_accuracy: 0.5708\n",
            "Epoch 147/200\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.5180 - accuracy: 0.7158 - val_loss: 1.5468 - val_accuracy: 0.5591\n",
            "Epoch 148/200\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.5125 - accuracy: 0.7200 - val_loss: 1.5379 - val_accuracy: 0.5594\n",
            "Epoch 149/200\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.5107 - accuracy: 0.7210 - val_loss: 1.6179 - val_accuracy: 0.5633\n",
            "Epoch 150/200\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7188 - val_loss: 1.5878 - val_accuracy: 0.5603\n",
            "Epoch 151/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7188 - val_loss: 1.5598 - val_accuracy: 0.5631\n",
            "Epoch 152/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7245 - val_loss: 1.8929 - val_accuracy: 0.5676\n",
            "Epoch 153/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7204 - val_loss: 1.6136 - val_accuracy: 0.5636\n",
            "Epoch 154/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7175 - val_loss: 1.8414 - val_accuracy: 0.5599\n",
            "Epoch 155/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7168 - val_loss: 1.6560 - val_accuracy: 0.5603\n",
            "Epoch 156/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7173 - val_loss: 1.6297 - val_accuracy: 0.5638\n",
            "Epoch 157/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7188 - val_loss: 1.6857 - val_accuracy: 0.5706\n",
            "Epoch 158/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7209 - val_loss: 1.6580 - val_accuracy: 0.5671\n",
            "Epoch 159/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7183 - val_loss: 1.6260 - val_accuracy: 0.5631\n",
            "Epoch 160/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7182 - val_loss: 1.6263 - val_accuracy: 0.5586\n",
            "Epoch 161/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7204 - val_loss: 1.7841 - val_accuracy: 0.5586\n",
            "Epoch 162/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7193 - val_loss: 1.7924 - val_accuracy: 0.5701\n",
            "Epoch 163/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7166 - val_loss: 1.5545 - val_accuracy: 0.5603\n",
            "Epoch 164/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7187 - val_loss: 1.7114 - val_accuracy: 0.5648\n",
            "Epoch 165/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7190 - val_loss: 1.8259 - val_accuracy: 0.5596\n",
            "Epoch 166/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7206 - val_loss: 1.7805 - val_accuracy: 0.5626\n",
            "Epoch 167/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7203 - val_loss: 1.5856 - val_accuracy: 0.5603\n",
            "Epoch 168/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7201 - val_loss: 1.8264 - val_accuracy: 0.5686\n",
            "Epoch 169/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7199 - val_loss: 1.7896 - val_accuracy: 0.5673\n",
            "Epoch 170/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7202 - val_loss: 1.7377 - val_accuracy: 0.5611\n",
            "Epoch 171/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7224 - val_loss: 1.7810 - val_accuracy: 0.5668\n",
            "Epoch 172/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7191 - val_loss: 1.8807 - val_accuracy: 0.5628\n",
            "Epoch 173/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7172 - val_loss: 1.8093 - val_accuracy: 0.5701\n",
            "Epoch 174/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7218 - val_loss: 1.7706 - val_accuracy: 0.5651\n",
            "Epoch 175/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7223 - val_loss: 1.6672 - val_accuracy: 0.5661\n",
            "Epoch 176/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7190 - val_loss: 1.7537 - val_accuracy: 0.5579\n",
            "Epoch 177/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7188 - val_loss: 1.8340 - val_accuracy: 0.5638\n",
            "Epoch 178/200\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.5085 - accuracy: 0.7183 - val_loss: 1.8758 - val_accuracy: 0.5623\n",
            "Epoch 179/200\n",
            "161/161 [==============================] - 1s 5ms/step - loss: 0.5080 - accuracy: 0.7214 - val_loss: 1.9500 - val_accuracy: 0.5651\n",
            "Epoch 180/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7190 - val_loss: 2.0326 - val_accuracy: 0.5678\n",
            "Epoch 181/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7205 - val_loss: 1.8672 - val_accuracy: 0.5596\n",
            "Epoch 182/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7196 - val_loss: 1.8954 - val_accuracy: 0.5599\n",
            "Epoch 183/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7209 - val_loss: 1.9568 - val_accuracy: 0.5646\n",
            "Epoch 184/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7226 - val_loss: 1.9232 - val_accuracy: 0.5594\n",
            "Epoch 185/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7211 - val_loss: 1.8565 - val_accuracy: 0.5653\n",
            "Epoch 186/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7197 - val_loss: 1.8764 - val_accuracy: 0.5676\n",
            "Epoch 187/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7199 - val_loss: 1.7732 - val_accuracy: 0.5608\n",
            "Epoch 188/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7224 - val_loss: 1.9279 - val_accuracy: 0.5646\n",
            "Epoch 189/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7198 - val_loss: 1.9794 - val_accuracy: 0.5673\n",
            "Epoch 190/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7203 - val_loss: 1.8581 - val_accuracy: 0.5683\n",
            "Epoch 191/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7214 - val_loss: 1.9398 - val_accuracy: 0.5681\n",
            "Epoch 192/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7204 - val_loss: 1.7537 - val_accuracy: 0.5678\n",
            "Epoch 193/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7202 - val_loss: 1.7671 - val_accuracy: 0.5641\n",
            "Epoch 194/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7246 - val_loss: 1.9383 - val_accuracy: 0.5628\n",
            "Epoch 195/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7237 - val_loss: 1.9195 - val_accuracy: 0.5713\n",
            "Epoch 196/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7219 - val_loss: 2.0179 - val_accuracy: 0.5599\n",
            "Epoch 197/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7184 - val_loss: 1.8998 - val_accuracy: 0.5606\n",
            "Epoch 198/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7207 - val_loss: 2.0054 - val_accuracy: 0.5566\n",
            "Epoch 199/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7223 - val_loss: 1.7726 - val_accuracy: 0.5666\n",
            "Epoch 200/200\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7214 - val_loss: 2.0059 - val_accuracy: 0.5623\n"
          ]
        }
      ],
      "source": [
        "#creating unique name for tensorboard directory\n",
        "log_dir = \"logs/NN/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "#Tensforboard callback function\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "tf.keras.utils.set_random_seed(973)\n",
        "\n",
        "struct = [30,30]\n",
        "dim = X_train.shape[1]\n",
        "model = NN_TF_model(structure = struct, ipt_dim = dim)\n",
        "history = model.fit(X_train,\n",
        "                  y_train,\n",
        "                  validation_split = 0.2,\n",
        "                  epochs=200,\n",
        "                  batch_size=100,\n",
        "                  shuffle=True,\n",
        "                  callbacks=[tensorboard_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "93d452b7",
      "metadata": {
        "id": "93d452b7",
        "outputId": "0b66daca-38e0-4bd3-e211-de550677095d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "model.test_on_batch(X_test, y_test)\n",
        "model.metrics_names\n",
        "print(history.history.keys())\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'b.', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'g', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# plt.figure()\n",
        "\n",
        "# plt.plot(epochs, loss, 'b.', label='Training loss')\n",
        "# plt.plot(epochs, val_loss, 'g', label='Validation loss')\n",
        "# plt.title('Training and validation loss')\n",
        "# plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "c54765a1",
      "metadata": {
        "id": "c54765a1"
      },
      "outputs": [],
      "source": [
        "m = metrics.Accuracy()\n",
        "mc = metrics.CategoricalAccuracy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "2d7c73df",
      "metadata": {
        "id": "2d7c73df"
      },
      "outputs": [],
      "source": [
        "y_hat=model.predict(X_train)>0.5\n",
        "y_hat=np.squeeze(y_hat)*1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "f3a998b3",
      "metadata": {
        "id": "f3a998b3",
        "outputId": "58bcab31-1513-4e0d-f7c9-1237c93faf3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "away win rate =  0.5272319201995013\n",
            "Train data accuracy 0.69426435\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[7154, 3805],\n",
              "       [2325, 6766]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "m.update_state(y_train, y_hat)\n",
        "mc.update_state(y_train, y_hat)\n",
        "print('away win rate = ', sum(y_hat)/len(y_hat))\n",
        "print('Train data accuracy',m.result().numpy())\n",
        "# print('Train data categorical accuracy',mc.result().numpy())\n",
        "tf.math.confusion_matrix(y_train, y_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "4fffbd65",
      "metadata": {
        "id": "4fffbd65"
      },
      "outputs": [],
      "source": [
        "#No separate validation set when using the full model\n",
        "#y_hat=model.predict(X_val)>0.5\n",
        "#y_hat=np.squeeze(y_hat)*1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#m.update_state(y_val, y_hat)\n",
        "#print('away win rate = ',sum(y_hat)/len(y_hat))\n",
        "#print('Test data accuracy',m.result().numpy())\n",
        "#tf.math.confusion_matrix(y_val, y_hat)"
      ],
      "metadata": {
        "id": "qAGCg0sWNtu-"
      },
      "id": "qAGCg0sWNtu-",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat=model.predict(X_test)>0.5\n",
        "y_hat=np.squeeze(y_hat)*1"
      ],
      "metadata": {
        "id": "jGTEDBRAN1tk"
      },
      "id": "jGTEDBRAN1tk",
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "d63e89aa",
      "metadata": {
        "id": "d63e89aa",
        "outputId": "f648c564-c083-46f2-a0e7-2ab56b17766c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "away win rate =  0.46373779637377965\n",
            "Test data accuracy 0.6826475\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[428, 347],\n",
              "       [341, 318]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "m.update_state(y_test, y_hat)\n",
        "print('away win rate = ',sum(y_hat)/len(y_hat))\n",
        "print('Test data accuracy',m.result().numpy())\n",
        "tf.math.confusion_matrix(y_test, y_hat)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def SeriesProb(model_prediction):\n",
        "    win = model_prediction\n",
        "    lose = 1-model_prediction\n",
        "    return win**4 * 1 + win**4 * lose**1 * 4 + win**4 * lose**2 * 10 + win**4 *  lose**3 * 20"
      ],
      "metadata": {
        "id": "skNGPF62OdWZ"
      },
      "id": "skNGPF62OdWZ",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "02122db1",
      "metadata": {
        "id": "02122db1",
        "outputId": "0ca0f0c8-5b5d-495b-835a-5ae1becb5766",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "SeriesProb(model.predict(X_pred)).shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "Xm1f-usMQQOR"
      },
      "id": "Xm1f-usMQQOR",
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## make the kfold object\n",
        "kfold = StratifiedKFold(5, random_state = 42, shuffle = True)\n",
        "\n",
        "\n",
        "ho_avgs = np.zeros(5)\n",
        "test_avgs = np.zeros(5)\n",
        "\n",
        "\n",
        "i = 0\n",
        "for train_index, test_index in kfold.split(X_train, y_train):\n",
        "    X_tt, X_ho = X_train[train_index], X_train[test_index]\n",
        "    y_tt, y_ho = y_train[train_index], y_train[test_index]\n",
        "\n",
        "\n",
        "    \n",
        "    ## Make the pipeline here\n",
        "    #pipe = Pipeline([('scale', StandardScaler()),\n",
        "    #                 ('log', LogisticRegression())])\n",
        "    #pipe = Pipeline([('ada', AdaBoostClassifier(DecisionTreeClassifier(max_depth = 1),\n",
        "    #                         n_estimators = 50, #The more estimators we use, the higher the training accuracy and lower the testing accuracy.\n",
        "    #                         learning_rate = 1,\n",
        "    #                         random_state = 2906))])\n",
        "    #pipe = Pipeline([('rf', RandomForestClassifier(n_estimators = 200,\n",
        "    #                            max_depth = 2))])\n",
        "    #pipe = Pipeline([('dt', DecisionTreeClassifier())])\n",
        "\n",
        "    ## fit the pipeline\n",
        "    pipe.fit(X_tt, y_tt)\n",
        "    \n",
        "    cutoff = 0.5\n",
        "    ## predict on the holdout set\n",
        "    y_hat_ho=np.squeeze(pipe.predict_proba(X_ho)[:,1]>cutoff)*1 \n",
        "    y_hat_test=np.squeeze(pipe.predict_proba(X_test)[:,1]>cutoff)*1 \n",
        "\n",
        "    ho_avgs[i] = accuracy_score(y_hat_ho, y_ho)\n",
        "    test_avgs[i] = accuracy_score(y_hat_test, y_test)\n",
        "    \n",
        "\n",
        "    i = i + 1\n",
        "\n",
        "print(np.mean(ho_avgs))\n",
        "print(np.mean(test_avgs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "vubvUxQQETJP",
        "outputId": "1d607404-7453-4a3c-d4eb-6ecb52c2bab3"
      },
      "id": "vubvUxQQETJP",
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-38068576ec57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m## fit the pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mcutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pipe' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Logistic Regression model"
      ],
      "metadata": {
        "id": "Z1ff0h__IvGE"
      },
      "id": "Z1ff0h__IvGE"
    },
    {
      "cell_type": "code",
      "source": [
        "log = LogisticRegression(random_state=4).fit(X_train, y_train)\n",
        "#np.hstack((log.predict(X_test), np.round(model.predict(X_test))))"
      ],
      "metadata": {
        "id": "FVOzm6NoTSzk"
      },
      "id": "FVOzm6NoTSzk",
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "HlrKjq7nTS2W",
        "outputId": "4c7aaeeb-7c7f-41d3-df7a-516ba4bf2cff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "HlrKjq7nTS2W",
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6224438902743142"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#No validation set when training the final model\n",
        "#log.score(X_val, y_val)"
      ],
      "metadata": {
        "id": "rv-bUem4TS5d"
      },
      "id": "rv-bUem4TS5d",
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "UD9F_q7KUDeK",
        "outputId": "d05e39c6-c7be-40e6-a5d5-3008ffe03ce9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UD9F_q7KUDeK",
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5285913528591353"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##AdaBoost model"
      ],
      "metadata": {
        "id": "U7VUOIz9XvHA"
      },
      "id": "U7VUOIz9XvHA"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier"
      ],
      "metadata": {
        "id": "bR-gTb8RUI6M"
      },
      "id": "bR-gTb8RUI6M",
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth = 2, random_state = 43210),\n",
        "                             n_estimators = 10, #The more estimators we use, the higher the training accuracy and lower the testing accuracy.\n",
        "                             learning_rate = 1,\n",
        "                             random_state = 2906)"
      ],
      "metadata": {
        "id": "8BUSLBiCX4oW"
      },
      "id": "8BUSLBiCX4oW",
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ada.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "iWU2PWCFX4re",
        "outputId": "f600fdab-8af3-4deb-a73c-d940a9572439",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "iWU2PWCFX4re",
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2,\n",
              "                                                         random_state=43210),\n",
              "                   learning_rate=1, n_estimators=10, random_state=2906)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ada.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "d50d4L3HX4uv",
        "outputId": "c7ae7dbd-4482-455e-c42a-ebd8cd62a79e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "d50d4L3HX4uv",
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6228927680798005"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#No validation set when training the final model\n",
        "#ada.score(X_val, y_val)"
      ],
      "metadata": {
        "id": "mZCJxeuAYQmF"
      },
      "id": "mZCJxeuAYQmF",
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ada.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "gjUOE37oYQqT",
        "outputId": "7338f6cd-a546-43de-d59f-47d105c73048",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "gjUOE37oYQqT",
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5327754532775453"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Random Forest model"
      ],
      "metadata": {
        "id": "jC5i9-jrRbzc"
      },
      "id": "jC5i9-jrRbzc"
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators = 500,\n",
        "                                max_depth = 5)"
      ],
      "metadata": {
        "id": "U1UoCIVBcd_G"
      },
      "id": "U1UoCIVBcd_G",
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "78J2tzFDce_M",
        "outputId": "dae59a37-4c40-4bd2-cbc6-819a1cd38bd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "78J2tzFDce_M",
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=5, n_estimators=500)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "l5N2sk1fcfCE",
        "outputId": "a8ac394f-064c-4f0c-8d9f-adccd9f2c91d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "l5N2sk1fcfCE",
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6295261845386534"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#No validation set when training the final model\n",
        "#rf.score(X_val, y_val)"
      ],
      "metadata": {
        "id": "kui93hN4cfE3"
      },
      "id": "kui93hN4cfE3",
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "11AFZqbZcmWI",
        "outputId": "58daec96-4bd3-45e6-d0c9-8d349a4efd61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "11AFZqbZcmWI",
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5439330543933054"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Find winning teams: Results"
      ],
      "metadata": {
        "id": "MF6XKsBYR8F6"
      },
      "id": "MF6XKsBYR8F6"
    },
    {
      "cell_type": "code",
      "source": [
        "#X_pred = X_test\n",
        "pred = np.zeros((4,len(X_pred)))"
      ],
      "metadata": {
        "id": "wBy-Wgt9YoEd"
      },
      "id": "wBy-Wgt9YoEd",
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred[0] = np.reshape(model.predict(X_pred), -1)\n",
        "pred[1] = log.predict_proba(X_pred)[:,1]\n",
        "pred[2] = ada.predict_proba(X_pred)[:,1]\n",
        "pred[3] = rf.predict_proba(X_pred)[:,1]"
      ],
      "metadata": {
        "id": "mWziPLTyfPiJ"
      },
      "id": "mWziPLTyfPiJ",
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_probs = SeriesProb(np.mean(pred, axis = 0))\n",
        "all_probs.shape"
      ],
      "metadata": {
        "id": "op0g9ZJvf6Eh",
        "outputId": "92de2784-b0e2-4247-dfa9-ad00c1dfd094",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "op0g9ZJvf6Eh",
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256,)"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_probs = np.mean(pred, axis = 0)\n",
        "y_hat=np.squeeze(test_probs>0.5)*1 \n",
        "\n",
        "accuracy_score(y_hat, y_t)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPKiulm2iUBj",
        "outputId": "342013a2-5b57-4120-f20c-e3454f3f3a65"
      },
      "id": "BPKiulm2iUBj",
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5334728033472803"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.ones(8) - SeriesProb(np.mean(pred, axis = 0)) #Probability of home team winning"
      ],
      "metadata": {
        "id": "IKMAN182gTr6",
        "outputId": "74fc8d6d-717e-4b84-bbef-df83e16bd410",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "IKMAN182gTr6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.89153731, 0.28872631, 0.74592029, 0.5716377 , 0.78158714,\n",
              "       0.43772545, 0.5170655 , 0.1955171 ])"
            ]
          },
          "metadata": {},
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Preddf = playoff_pred[column_name]\n",
        "PredX_array = Preddf[column_name[1:]].to_numpy()"
      ],
      "metadata": {
        "id": "D5083Mf1ghZd"
      },
      "id": "D5083Mf1ghZd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TeamAverages.to_csv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "AGHQJ7guKnE0",
        "outputId": "62f986cc-546a-4da5-e898-cd9247d94358"
      },
      "id": "AGHQJ7guKnE0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "',homeAbbrev,F_home_assists,F_home_goals,F_home_pim,F_home_shots,F_home_blocked,F_home_hits,F_home_pm,D_home_assists,D_home_goals,D_home_pim,D_home_shots,D_home_blocked,D_home_hits,D_home_pm,G_home_GAA\\n0,COL,1.354877487,0.897446483,1.693629899,7.865988533,2.007969868,4.694978402,0.483298655,1.01274733,0.377212453,1.725934568,4.977004966,3.666825358,4.88198029,0.618378102,3.079092317\\n1,NSH,1.147840536,0.864017655,2.642927453,6.676903494,2.109019801,7.565426937,-0.011657052,0.869902561,0.188684924,3.097599196,4.577686611,4.089691224,5.819146186,-0.028378617,3.179254064\\n2,MIN,1.454758563,0.871290649,3.463297582,8.113439119,1.710650098,7.158113545,0.428524482,0.802816143,0.241591467,1.353865648,3.969292371,4.108469387,3.713037451,0.903035368,2.9042\\n3,STL,1.610159619,1.099072949,1.337460667,7.288216798,1.554598659,3.899510146,0.317211223,0.927065216,0.247134288,1.52225029,4.026447761,3.868756204,3.642786063,0.276109114,2.846504078\\n4,CGY,1.270271312,1.002407148,1.804617636,8.304611662,1.407936586,5.228458073,0.70820923,1.059639775,0.248739187,1.857671886,5.465384704,3.756103989,4.240612165,0.683348567,2.2241\\n5,DAL,0.97750581,0.709077264,1.346790881,6.725737866,2.068484792,5.346604971,-0.454930946,0.789127426,0.180639912,1.113347277,4.23301397,3.808292779,3.781154355,-0.309382392,2.5262\\n6,EDM,1.270052852,0.930354147,2.022098521,7.384277727,1.295796739,6.416884786,0.395703008,0.863851093,0.225267778,1.137327938,5.099718816,4.318836565,4.65988642,-0.601595437,2.712706836\\n7,LAK,0.951035236,0.873423505,1.903911894,8.545825489,1.639261736,4.187482263,0.013352675,0.674483496,0.10467802,1.027555461,4.446804074,4.22974833,4.207890182,0.205610669,2.5913\\n8,FLA,1.644462156,1.140086548,2.132879675,8.435700865,1.585192815,4.8905102,0.854797088,0.920504742,0.306455616,1.981336399,5.470553476,4.065650688,6.073889774,0.694921021,3.548597532\\n9,WSH,1.238918194,0.859158775,1.728239596,7.078065781,1.956336265,5.427952427,-0.045068982,0.835282494,0.301263622,1.486158905,4.583104139,4.43277396,4.906950462,0.270856604,3.062783502\\n10,TOR,1.316698432,0.998463755,1.79640962,8.70037122,1.834604442,4.528443383,0.111124713,1.058656887,0.193572452,1.824681279,4.575004136,3.692434319,5.501247737,0.259144698,3.397820631\\n11,TBL,1.21852271,0.954218093,2.040474799,7.420484035,1.58320129,5.424255715,-0.340504553,0.832702295,0.211923465,1.746098776,4.481311022,4.361285588,5.699697563,0.437692616,4.881897903\\n12,CAR,1.297849449,0.945376341,1.815331061,7.61191162,1.22120489,5.118140638,0.659152571,1.01618353,0.278281026,1.978205793,5.807337816,3.483390085,3.162029234,0.72092847,3.250879387\\n13,BOS,1.047789393,0.776380471,2.24206983,8.409460261,1.651911794,7.984761885,-0.225282924,0.613150198,0.21139932,2.662175222,4.673747948,3.824459411,5.003442222,-0.096108976,2.4098\\n14,NYR,1.059499173,0.769644987,1.540431458,6.982735451,1.897343801,5.403890533,0.240290914,0.700100603,0.235790317,1.540026925,3.887424618,4.870492163,4.548691821,-0.208204563,2.035025269\\n15,PIT,1.29077148,1.020564054,1.209887481,8.642700622,1.821980573,4.321031815,0.320897728,0.920524631,0.188419087,1.81915795,4.724364562,3.994382951,4.6442776,0.266194759,2.402008972\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code:\n",
        "* create a dataframe of all 16 teams, with 15 points of data each.\n",
        "\n",
        "*   loop through each pair of teams in the dataframe and predict who'd win a matchup between them.\n",
        "*   calculate the predicted probabilities of progressing to the final\n",
        "*   do that with a script and not by hand\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nz6XqqXKGi8R"
      },
      "id": "nz6XqqXKGi8R"
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(all_indices)):\n",
        "    print(TeamAverages.homeAbbrev.loc[all_indices[i,0]], \"vs \", TeamAverages.homeAbbrev.loc[all_indices[i,1]])\n",
        "    print(all_probs[i],'\\n\\n')"
      ],
      "metadata": {
        "id": "ecfWtub0b7Jo"
      },
      "id": "ecfWtub0b7Jo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_probs =  np.reshape(model.predict(X_pred), -1)\n",
        "#all_probs = log.predict_proba(X_pred)[:,1]\n",
        "#all_probs = ada.predict_proba(X_pred)[:,1]\n",
        "#all_probs = rf.predict_proba(X_pred)[:,1]"
      ],
      "metadata": {
        "id": "V6K7fwuPevHa"
      },
      "id": "V6K7fwuPevHa",
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#my_columns = np.hstack(('home_team',TeamList))\n",
        "funky_prob_table = pd.DataFrame(columns = [TeamList])\n",
        "funky_prob_table = pd.DataFrame(all_probs.reshape(-1,16), index = TeamList,columns = funky_prob_table.columns) \n",
        "funky_prob_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "H9oEMsiuevSn",
        "outputId": "bec981b1-c66f-4c08-cff0-003bae30f4ae"
      },
      "id": "H9oEMsiuevSn",
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          COL       NSH       MIN       STL       CGY       DAL       EDM  \\\n",
              "COL  0.424484  0.378109  0.603866  0.494253  0.387087  0.431681  0.325324   \n",
              "NSH  0.551401  0.587866  0.421329  0.578173  0.588453  0.385065  0.619882   \n",
              "MIN  0.578137  0.293207  0.401232  0.589728  0.396833  0.360053  0.321580   \n",
              "STL  0.455921  0.405783  0.572191  0.479538  0.506072  0.416888  0.308229   \n",
              "CGY  0.430533  0.420977  0.514769  0.419461  0.426104  0.345027  0.533849   \n",
              "DAL  0.477700  0.345849  0.439031  0.553887  0.604544  0.479324  0.385253   \n",
              "EDM  0.508074  0.323725  0.630234  0.533759  0.554347  0.403722  0.490798   \n",
              "LAK  0.619461  0.376436  0.514524  0.609524  0.679849  0.414262  0.591016   \n",
              "FLA  0.518931  0.483218  0.424435  0.489849  0.545258  0.488715  0.323139   \n",
              "WSH  0.514241  0.383876  0.642633  0.531593  0.520498  0.501976  0.357492   \n",
              "TOR  0.599138  0.533621  0.628743  0.619264  0.648719  0.570105  0.574263   \n",
              "TBL  0.699836  0.411717  0.722453  0.497830  0.729483  0.665652  0.451905   \n",
              "CAR  0.558105  0.303564  0.616964  0.374989  0.649421  0.478744  0.336862   \n",
              "BOS  0.522128  0.346061  0.489057  0.502095  0.610986  0.389460  0.511196   \n",
              "NYR  0.481682  0.300753  0.530350  0.442275  0.656796  0.352266  0.336697   \n",
              "PIT  0.396356  0.402641  0.440369  0.474301  0.486838  0.398836  0.555152   \n",
              "\n",
              "          LAK       FLA       WSH       TOR       TBL       CAR       BOS  \\\n",
              "COL  0.554211  0.338489  0.317382  0.333988  0.183781  0.331562  0.406418   \n",
              "NSH  0.503752  0.603817  0.514783  0.603525  0.290504  0.583435  0.507147   \n",
              "MIN  0.320887  0.580159  0.340727  0.323080  0.178667  0.378379  0.311703   \n",
              "STL  0.548117  0.399711  0.429996  0.362093  0.132032  0.390783  0.360984   \n",
              "CGY  0.407509  0.421037  0.391486  0.452913  0.152777  0.287473  0.278084   \n",
              "DAL  0.558113  0.514442  0.490250  0.495366  0.208605  0.431167  0.618732   \n",
              "EDM  0.607646  0.456530  0.466270  0.539007  0.375969  0.424456  0.364486   \n",
              "LAK  0.500831  0.401336  0.344505  0.376482  0.150414  0.379272  0.513127   \n",
              "FLA  0.344697  0.392210  0.562255  0.333266  0.219403  0.326779  0.376210   \n",
              "WSH  0.600856  0.600043  0.455784  0.449261  0.205824  0.376317  0.529380   \n",
              "TOR  0.588318  0.396491  0.557972  0.376230  0.164071  0.370267  0.348821   \n",
              "TBL  0.693253  0.459178  0.488620  0.433323  0.221178  0.584644  0.680114   \n",
              "CAR  0.584869  0.481475  0.524780  0.322253  0.221854  0.341778  0.427839   \n",
              "BOS  0.502673  0.466983  0.488437  0.431743  0.165301  0.624841  0.462180   \n",
              "NYR  0.416745  0.408595  0.384919  0.336364  0.141179  0.413389  0.456727   \n",
              "PIT  0.424068  0.368660  0.414814  0.387573  0.119128  0.318266  0.353971   \n",
              "\n",
              "          NYR       PIT  \n",
              "COL  0.346262  0.436084  \n",
              "NSH  0.542944  0.595895  \n",
              "MIN  0.340776  0.384604  \n",
              "STL  0.345006  0.486478  \n",
              "CGY  0.364370  0.445860  \n",
              "DAL  0.569724  0.674964  \n",
              "EDM  0.382929  0.540466  \n",
              "LAK  0.613678  0.656864  \n",
              "FLA  0.344517  0.587925  \n",
              "WSH  0.375864  0.537012  \n",
              "TOR  0.508009  0.529412  \n",
              "TBL  0.630812  0.611655  \n",
              "CAR  0.356469  0.631891  \n",
              "BOS  0.506355  0.512230  \n",
              "NYR  0.424691  0.467589  \n",
              "PIT  0.455279  0.442255  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c67d1b5-971f-4099-9b25-00a7a0c78359\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>COL</th>\n",
              "      <th>NSH</th>\n",
              "      <th>MIN</th>\n",
              "      <th>STL</th>\n",
              "      <th>CGY</th>\n",
              "      <th>DAL</th>\n",
              "      <th>EDM</th>\n",
              "      <th>LAK</th>\n",
              "      <th>FLA</th>\n",
              "      <th>WSH</th>\n",
              "      <th>TOR</th>\n",
              "      <th>TBL</th>\n",
              "      <th>CAR</th>\n",
              "      <th>BOS</th>\n",
              "      <th>NYR</th>\n",
              "      <th>PIT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>COL</th>\n",
              "      <td>0.424484</td>\n",
              "      <td>0.378109</td>\n",
              "      <td>0.603866</td>\n",
              "      <td>0.494253</td>\n",
              "      <td>0.387087</td>\n",
              "      <td>0.431681</td>\n",
              "      <td>0.325324</td>\n",
              "      <td>0.554211</td>\n",
              "      <td>0.338489</td>\n",
              "      <td>0.317382</td>\n",
              "      <td>0.333988</td>\n",
              "      <td>0.183781</td>\n",
              "      <td>0.331562</td>\n",
              "      <td>0.406418</td>\n",
              "      <td>0.346262</td>\n",
              "      <td>0.436084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NSH</th>\n",
              "      <td>0.551401</td>\n",
              "      <td>0.587866</td>\n",
              "      <td>0.421329</td>\n",
              "      <td>0.578173</td>\n",
              "      <td>0.588453</td>\n",
              "      <td>0.385065</td>\n",
              "      <td>0.619882</td>\n",
              "      <td>0.503752</td>\n",
              "      <td>0.603817</td>\n",
              "      <td>0.514783</td>\n",
              "      <td>0.603525</td>\n",
              "      <td>0.290504</td>\n",
              "      <td>0.583435</td>\n",
              "      <td>0.507147</td>\n",
              "      <td>0.542944</td>\n",
              "      <td>0.595895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MIN</th>\n",
              "      <td>0.578137</td>\n",
              "      <td>0.293207</td>\n",
              "      <td>0.401232</td>\n",
              "      <td>0.589728</td>\n",
              "      <td>0.396833</td>\n",
              "      <td>0.360053</td>\n",
              "      <td>0.321580</td>\n",
              "      <td>0.320887</td>\n",
              "      <td>0.580159</td>\n",
              "      <td>0.340727</td>\n",
              "      <td>0.323080</td>\n",
              "      <td>0.178667</td>\n",
              "      <td>0.378379</td>\n",
              "      <td>0.311703</td>\n",
              "      <td>0.340776</td>\n",
              "      <td>0.384604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>STL</th>\n",
              "      <td>0.455921</td>\n",
              "      <td>0.405783</td>\n",
              "      <td>0.572191</td>\n",
              "      <td>0.479538</td>\n",
              "      <td>0.506072</td>\n",
              "      <td>0.416888</td>\n",
              "      <td>0.308229</td>\n",
              "      <td>0.548117</td>\n",
              "      <td>0.399711</td>\n",
              "      <td>0.429996</td>\n",
              "      <td>0.362093</td>\n",
              "      <td>0.132032</td>\n",
              "      <td>0.390783</td>\n",
              "      <td>0.360984</td>\n",
              "      <td>0.345006</td>\n",
              "      <td>0.486478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CGY</th>\n",
              "      <td>0.430533</td>\n",
              "      <td>0.420977</td>\n",
              "      <td>0.514769</td>\n",
              "      <td>0.419461</td>\n",
              "      <td>0.426104</td>\n",
              "      <td>0.345027</td>\n",
              "      <td>0.533849</td>\n",
              "      <td>0.407509</td>\n",
              "      <td>0.421037</td>\n",
              "      <td>0.391486</td>\n",
              "      <td>0.452913</td>\n",
              "      <td>0.152777</td>\n",
              "      <td>0.287473</td>\n",
              "      <td>0.278084</td>\n",
              "      <td>0.364370</td>\n",
              "      <td>0.445860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DAL</th>\n",
              "      <td>0.477700</td>\n",
              "      <td>0.345849</td>\n",
              "      <td>0.439031</td>\n",
              "      <td>0.553887</td>\n",
              "      <td>0.604544</td>\n",
              "      <td>0.479324</td>\n",
              "      <td>0.385253</td>\n",
              "      <td>0.558113</td>\n",
              "      <td>0.514442</td>\n",
              "      <td>0.490250</td>\n",
              "      <td>0.495366</td>\n",
              "      <td>0.208605</td>\n",
              "      <td>0.431167</td>\n",
              "      <td>0.618732</td>\n",
              "      <td>0.569724</td>\n",
              "      <td>0.674964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EDM</th>\n",
              "      <td>0.508074</td>\n",
              "      <td>0.323725</td>\n",
              "      <td>0.630234</td>\n",
              "      <td>0.533759</td>\n",
              "      <td>0.554347</td>\n",
              "      <td>0.403722</td>\n",
              "      <td>0.490798</td>\n",
              "      <td>0.607646</td>\n",
              "      <td>0.456530</td>\n",
              "      <td>0.466270</td>\n",
              "      <td>0.539007</td>\n",
              "      <td>0.375969</td>\n",
              "      <td>0.424456</td>\n",
              "      <td>0.364486</td>\n",
              "      <td>0.382929</td>\n",
              "      <td>0.540466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LAK</th>\n",
              "      <td>0.619461</td>\n",
              "      <td>0.376436</td>\n",
              "      <td>0.514524</td>\n",
              "      <td>0.609524</td>\n",
              "      <td>0.679849</td>\n",
              "      <td>0.414262</td>\n",
              "      <td>0.591016</td>\n",
              "      <td>0.500831</td>\n",
              "      <td>0.401336</td>\n",
              "      <td>0.344505</td>\n",
              "      <td>0.376482</td>\n",
              "      <td>0.150414</td>\n",
              "      <td>0.379272</td>\n",
              "      <td>0.513127</td>\n",
              "      <td>0.613678</td>\n",
              "      <td>0.656864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FLA</th>\n",
              "      <td>0.518931</td>\n",
              "      <td>0.483218</td>\n",
              "      <td>0.424435</td>\n",
              "      <td>0.489849</td>\n",
              "      <td>0.545258</td>\n",
              "      <td>0.488715</td>\n",
              "      <td>0.323139</td>\n",
              "      <td>0.344697</td>\n",
              "      <td>0.392210</td>\n",
              "      <td>0.562255</td>\n",
              "      <td>0.333266</td>\n",
              "      <td>0.219403</td>\n",
              "      <td>0.326779</td>\n",
              "      <td>0.376210</td>\n",
              "      <td>0.344517</td>\n",
              "      <td>0.587925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WSH</th>\n",
              "      <td>0.514241</td>\n",
              "      <td>0.383876</td>\n",
              "      <td>0.642633</td>\n",
              "      <td>0.531593</td>\n",
              "      <td>0.520498</td>\n",
              "      <td>0.501976</td>\n",
              "      <td>0.357492</td>\n",
              "      <td>0.600856</td>\n",
              "      <td>0.600043</td>\n",
              "      <td>0.455784</td>\n",
              "      <td>0.449261</td>\n",
              "      <td>0.205824</td>\n",
              "      <td>0.376317</td>\n",
              "      <td>0.529380</td>\n",
              "      <td>0.375864</td>\n",
              "      <td>0.537012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TOR</th>\n",
              "      <td>0.599138</td>\n",
              "      <td>0.533621</td>\n",
              "      <td>0.628743</td>\n",
              "      <td>0.619264</td>\n",
              "      <td>0.648719</td>\n",
              "      <td>0.570105</td>\n",
              "      <td>0.574263</td>\n",
              "      <td>0.588318</td>\n",
              "      <td>0.396491</td>\n",
              "      <td>0.557972</td>\n",
              "      <td>0.376230</td>\n",
              "      <td>0.164071</td>\n",
              "      <td>0.370267</td>\n",
              "      <td>0.348821</td>\n",
              "      <td>0.508009</td>\n",
              "      <td>0.529412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TBL</th>\n",
              "      <td>0.699836</td>\n",
              "      <td>0.411717</td>\n",
              "      <td>0.722453</td>\n",
              "      <td>0.497830</td>\n",
              "      <td>0.729483</td>\n",
              "      <td>0.665652</td>\n",
              "      <td>0.451905</td>\n",
              "      <td>0.693253</td>\n",
              "      <td>0.459178</td>\n",
              "      <td>0.488620</td>\n",
              "      <td>0.433323</td>\n",
              "      <td>0.221178</td>\n",
              "      <td>0.584644</td>\n",
              "      <td>0.680114</td>\n",
              "      <td>0.630812</td>\n",
              "      <td>0.611655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CAR</th>\n",
              "      <td>0.558105</td>\n",
              "      <td>0.303564</td>\n",
              "      <td>0.616964</td>\n",
              "      <td>0.374989</td>\n",
              "      <td>0.649421</td>\n",
              "      <td>0.478744</td>\n",
              "      <td>0.336862</td>\n",
              "      <td>0.584869</td>\n",
              "      <td>0.481475</td>\n",
              "      <td>0.524780</td>\n",
              "      <td>0.322253</td>\n",
              "      <td>0.221854</td>\n",
              "      <td>0.341778</td>\n",
              "      <td>0.427839</td>\n",
              "      <td>0.356469</td>\n",
              "      <td>0.631891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BOS</th>\n",
              "      <td>0.522128</td>\n",
              "      <td>0.346061</td>\n",
              "      <td>0.489057</td>\n",
              "      <td>0.502095</td>\n",
              "      <td>0.610986</td>\n",
              "      <td>0.389460</td>\n",
              "      <td>0.511196</td>\n",
              "      <td>0.502673</td>\n",
              "      <td>0.466983</td>\n",
              "      <td>0.488437</td>\n",
              "      <td>0.431743</td>\n",
              "      <td>0.165301</td>\n",
              "      <td>0.624841</td>\n",
              "      <td>0.462180</td>\n",
              "      <td>0.506355</td>\n",
              "      <td>0.512230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NYR</th>\n",
              "      <td>0.481682</td>\n",
              "      <td>0.300753</td>\n",
              "      <td>0.530350</td>\n",
              "      <td>0.442275</td>\n",
              "      <td>0.656796</td>\n",
              "      <td>0.352266</td>\n",
              "      <td>0.336697</td>\n",
              "      <td>0.416745</td>\n",
              "      <td>0.408595</td>\n",
              "      <td>0.384919</td>\n",
              "      <td>0.336364</td>\n",
              "      <td>0.141179</td>\n",
              "      <td>0.413389</td>\n",
              "      <td>0.456727</td>\n",
              "      <td>0.424691</td>\n",
              "      <td>0.467589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PIT</th>\n",
              "      <td>0.396356</td>\n",
              "      <td>0.402641</td>\n",
              "      <td>0.440369</td>\n",
              "      <td>0.474301</td>\n",
              "      <td>0.486838</td>\n",
              "      <td>0.398836</td>\n",
              "      <td>0.555152</td>\n",
              "      <td>0.424068</td>\n",
              "      <td>0.368660</td>\n",
              "      <td>0.414814</td>\n",
              "      <td>0.387573</td>\n",
              "      <td>0.119128</td>\n",
              "      <td>0.318266</td>\n",
              "      <td>0.353971</td>\n",
              "      <td>0.455279</td>\n",
              "      <td>0.442255</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c67d1b5-971f-4099-9b25-00a7a0c78359')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c67d1b5-971f-4099-9b25-00a7a0c78359 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c67d1b5-971f-4099-9b25-00a7a0c78359');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This is the probability of the home team winning the game\n",
        "Home_table = pd.DataFrame(np.ones((16,16)) - all_probs.reshape(-1,16), index = TeamList, columns = funky_prob_table.columns) \n",
        "Home_table#.to_csv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "BcHt1KbcjrGK",
        "outputId": "851e8d2c-da00-4b38-bd87-a06de5ced45b"
      },
      "id": "BcHt1KbcjrGK",
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          COL       NSH       MIN       STL       CGY       DAL       EDM  \\\n",
              "COL  0.575516  0.621891  0.396134  0.505747  0.612913  0.568319  0.674676   \n",
              "NSH  0.448599  0.412134  0.578671  0.421827  0.411547  0.614935  0.380118   \n",
              "MIN  0.421863  0.706793  0.598768  0.410272  0.603167  0.639947  0.678420   \n",
              "STL  0.544079  0.594217  0.427809  0.520462  0.493928  0.583112  0.691771   \n",
              "CGY  0.569467  0.579023  0.485231  0.580539  0.573896  0.654973  0.466151   \n",
              "DAL  0.522300  0.654151  0.560969  0.446113  0.395456  0.520676  0.614747   \n",
              "EDM  0.491926  0.676275  0.369766  0.466241  0.445653  0.596278  0.509202   \n",
              "LAK  0.380539  0.623564  0.485476  0.390476  0.320151  0.585738  0.408984   \n",
              "FLA  0.481069  0.516782  0.575565  0.510151  0.454742  0.511285  0.676861   \n",
              "WSH  0.485759  0.616124  0.357367  0.468407  0.479502  0.498024  0.642508   \n",
              "TOR  0.400862  0.466379  0.371257  0.380736  0.351281  0.429895  0.425737   \n",
              "TBL  0.300164  0.588283  0.277547  0.502170  0.270517  0.334348  0.548095   \n",
              "CAR  0.441895  0.696436  0.383036  0.625011  0.350579  0.521256  0.663138   \n",
              "BOS  0.477872  0.653939  0.510943  0.497905  0.389014  0.610540  0.488804   \n",
              "NYR  0.518318  0.699247  0.469650  0.557725  0.343204  0.647734  0.663303   \n",
              "PIT  0.603644  0.597359  0.559631  0.525699  0.513162  0.601164  0.444848   \n",
              "\n",
              "          LAK       FLA       WSH       TOR       TBL       CAR       BOS  \\\n",
              "COL  0.445789  0.661511  0.682618  0.666012  0.816219  0.668438  0.593582   \n",
              "NSH  0.496248  0.396183  0.485217  0.396475  0.709496  0.416565  0.492853   \n",
              "MIN  0.679113  0.419841  0.659273  0.676920  0.821333  0.621621  0.688297   \n",
              "STL  0.451883  0.600289  0.570004  0.637907  0.867968  0.609217  0.639016   \n",
              "CGY  0.592491  0.578963  0.608514  0.547087  0.847223  0.712527  0.721916   \n",
              "DAL  0.441887  0.485558  0.509750  0.504634  0.791395  0.568833  0.381268   \n",
              "EDM  0.392354  0.543470  0.533730  0.460993  0.624031  0.575544  0.635514   \n",
              "LAK  0.499169  0.598664  0.655495  0.623518  0.849586  0.620728  0.486873   \n",
              "FLA  0.655303  0.607790  0.437745  0.666734  0.780597  0.673221  0.623790   \n",
              "WSH  0.399144  0.399957  0.544216  0.550739  0.794176  0.623683  0.470620   \n",
              "TOR  0.411682  0.603509  0.442028  0.623770  0.835929  0.629733  0.651179   \n",
              "TBL  0.306747  0.540822  0.511380  0.566677  0.778822  0.415356  0.319886   \n",
              "CAR  0.415131  0.518525  0.475220  0.677747  0.778146  0.658222  0.572161   \n",
              "BOS  0.497327  0.533017  0.511563  0.568257  0.834699  0.375159  0.537820   \n",
              "NYR  0.583255  0.591405  0.615081  0.663636  0.858821  0.586611  0.543273   \n",
              "PIT  0.575932  0.631340  0.585186  0.612427  0.880872  0.681734  0.646029   \n",
              "\n",
              "          NYR       PIT  \n",
              "COL  0.653738  0.563916  \n",
              "NSH  0.457056  0.404105  \n",
              "MIN  0.659224  0.615396  \n",
              "STL  0.654994  0.513522  \n",
              "CGY  0.635630  0.554140  \n",
              "DAL  0.430276  0.325036  \n",
              "EDM  0.617071  0.459534  \n",
              "LAK  0.386322  0.343136  \n",
              "FLA  0.655483  0.412075  \n",
              "WSH  0.624136  0.462988  \n",
              "TOR  0.491991  0.470588  \n",
              "TBL  0.369188  0.388345  \n",
              "CAR  0.643531  0.368109  \n",
              "BOS  0.493645  0.487770  \n",
              "NYR  0.575309  0.532411  \n",
              "PIT  0.544721  0.557745  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd0176d9-777b-4407-b78d-f158a5c655ac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>COL</th>\n",
              "      <th>NSH</th>\n",
              "      <th>MIN</th>\n",
              "      <th>STL</th>\n",
              "      <th>CGY</th>\n",
              "      <th>DAL</th>\n",
              "      <th>EDM</th>\n",
              "      <th>LAK</th>\n",
              "      <th>FLA</th>\n",
              "      <th>WSH</th>\n",
              "      <th>TOR</th>\n",
              "      <th>TBL</th>\n",
              "      <th>CAR</th>\n",
              "      <th>BOS</th>\n",
              "      <th>NYR</th>\n",
              "      <th>PIT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>COL</th>\n",
              "      <td>0.575516</td>\n",
              "      <td>0.621891</td>\n",
              "      <td>0.396134</td>\n",
              "      <td>0.505747</td>\n",
              "      <td>0.612913</td>\n",
              "      <td>0.568319</td>\n",
              "      <td>0.674676</td>\n",
              "      <td>0.445789</td>\n",
              "      <td>0.661511</td>\n",
              "      <td>0.682618</td>\n",
              "      <td>0.666012</td>\n",
              "      <td>0.816219</td>\n",
              "      <td>0.668438</td>\n",
              "      <td>0.593582</td>\n",
              "      <td>0.653738</td>\n",
              "      <td>0.563916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NSH</th>\n",
              "      <td>0.448599</td>\n",
              "      <td>0.412134</td>\n",
              "      <td>0.578671</td>\n",
              "      <td>0.421827</td>\n",
              "      <td>0.411547</td>\n",
              "      <td>0.614935</td>\n",
              "      <td>0.380118</td>\n",
              "      <td>0.496248</td>\n",
              "      <td>0.396183</td>\n",
              "      <td>0.485217</td>\n",
              "      <td>0.396475</td>\n",
              "      <td>0.709496</td>\n",
              "      <td>0.416565</td>\n",
              "      <td>0.492853</td>\n",
              "      <td>0.457056</td>\n",
              "      <td>0.404105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MIN</th>\n",
              "      <td>0.421863</td>\n",
              "      <td>0.706793</td>\n",
              "      <td>0.598768</td>\n",
              "      <td>0.410272</td>\n",
              "      <td>0.603167</td>\n",
              "      <td>0.639947</td>\n",
              "      <td>0.678420</td>\n",
              "      <td>0.679113</td>\n",
              "      <td>0.419841</td>\n",
              "      <td>0.659273</td>\n",
              "      <td>0.676920</td>\n",
              "      <td>0.821333</td>\n",
              "      <td>0.621621</td>\n",
              "      <td>0.688297</td>\n",
              "      <td>0.659224</td>\n",
              "      <td>0.615396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>STL</th>\n",
              "      <td>0.544079</td>\n",
              "      <td>0.594217</td>\n",
              "      <td>0.427809</td>\n",
              "      <td>0.520462</td>\n",
              "      <td>0.493928</td>\n",
              "      <td>0.583112</td>\n",
              "      <td>0.691771</td>\n",
              "      <td>0.451883</td>\n",
              "      <td>0.600289</td>\n",
              "      <td>0.570004</td>\n",
              "      <td>0.637907</td>\n",
              "      <td>0.867968</td>\n",
              "      <td>0.609217</td>\n",
              "      <td>0.639016</td>\n",
              "      <td>0.654994</td>\n",
              "      <td>0.513522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CGY</th>\n",
              "      <td>0.569467</td>\n",
              "      <td>0.579023</td>\n",
              "      <td>0.485231</td>\n",
              "      <td>0.580539</td>\n",
              "      <td>0.573896</td>\n",
              "      <td>0.654973</td>\n",
              "      <td>0.466151</td>\n",
              "      <td>0.592491</td>\n",
              "      <td>0.578963</td>\n",
              "      <td>0.608514</td>\n",
              "      <td>0.547087</td>\n",
              "      <td>0.847223</td>\n",
              "      <td>0.712527</td>\n",
              "      <td>0.721916</td>\n",
              "      <td>0.635630</td>\n",
              "      <td>0.554140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DAL</th>\n",
              "      <td>0.522300</td>\n",
              "      <td>0.654151</td>\n",
              "      <td>0.560969</td>\n",
              "      <td>0.446113</td>\n",
              "      <td>0.395456</td>\n",
              "      <td>0.520676</td>\n",
              "      <td>0.614747</td>\n",
              "      <td>0.441887</td>\n",
              "      <td>0.485558</td>\n",
              "      <td>0.509750</td>\n",
              "      <td>0.504634</td>\n",
              "      <td>0.791395</td>\n",
              "      <td>0.568833</td>\n",
              "      <td>0.381268</td>\n",
              "      <td>0.430276</td>\n",
              "      <td>0.325036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EDM</th>\n",
              "      <td>0.491926</td>\n",
              "      <td>0.676275</td>\n",
              "      <td>0.369766</td>\n",
              "      <td>0.466241</td>\n",
              "      <td>0.445653</td>\n",
              "      <td>0.596278</td>\n",
              "      <td>0.509202</td>\n",
              "      <td>0.392354</td>\n",
              "      <td>0.543470</td>\n",
              "      <td>0.533730</td>\n",
              "      <td>0.460993</td>\n",
              "      <td>0.624031</td>\n",
              "      <td>0.575544</td>\n",
              "      <td>0.635514</td>\n",
              "      <td>0.617071</td>\n",
              "      <td>0.459534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LAK</th>\n",
              "      <td>0.380539</td>\n",
              "      <td>0.623564</td>\n",
              "      <td>0.485476</td>\n",
              "      <td>0.390476</td>\n",
              "      <td>0.320151</td>\n",
              "      <td>0.585738</td>\n",
              "      <td>0.408984</td>\n",
              "      <td>0.499169</td>\n",
              "      <td>0.598664</td>\n",
              "      <td>0.655495</td>\n",
              "      <td>0.623518</td>\n",
              "      <td>0.849586</td>\n",
              "      <td>0.620728</td>\n",
              "      <td>0.486873</td>\n",
              "      <td>0.386322</td>\n",
              "      <td>0.343136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FLA</th>\n",
              "      <td>0.481069</td>\n",
              "      <td>0.516782</td>\n",
              "      <td>0.575565</td>\n",
              "      <td>0.510151</td>\n",
              "      <td>0.454742</td>\n",
              "      <td>0.511285</td>\n",
              "      <td>0.676861</td>\n",
              "      <td>0.655303</td>\n",
              "      <td>0.607790</td>\n",
              "      <td>0.437745</td>\n",
              "      <td>0.666734</td>\n",
              "      <td>0.780597</td>\n",
              "      <td>0.673221</td>\n",
              "      <td>0.623790</td>\n",
              "      <td>0.655483</td>\n",
              "      <td>0.412075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WSH</th>\n",
              "      <td>0.485759</td>\n",
              "      <td>0.616124</td>\n",
              "      <td>0.357367</td>\n",
              "      <td>0.468407</td>\n",
              "      <td>0.479502</td>\n",
              "      <td>0.498024</td>\n",
              "      <td>0.642508</td>\n",
              "      <td>0.399144</td>\n",
              "      <td>0.399957</td>\n",
              "      <td>0.544216</td>\n",
              "      <td>0.550739</td>\n",
              "      <td>0.794176</td>\n",
              "      <td>0.623683</td>\n",
              "      <td>0.470620</td>\n",
              "      <td>0.624136</td>\n",
              "      <td>0.462988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TOR</th>\n",
              "      <td>0.400862</td>\n",
              "      <td>0.466379</td>\n",
              "      <td>0.371257</td>\n",
              "      <td>0.380736</td>\n",
              "      <td>0.351281</td>\n",
              "      <td>0.429895</td>\n",
              "      <td>0.425737</td>\n",
              "      <td>0.411682</td>\n",
              "      <td>0.603509</td>\n",
              "      <td>0.442028</td>\n",
              "      <td>0.623770</td>\n",
              "      <td>0.835929</td>\n",
              "      <td>0.629733</td>\n",
              "      <td>0.651179</td>\n",
              "      <td>0.491991</td>\n",
              "      <td>0.470588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TBL</th>\n",
              "      <td>0.300164</td>\n",
              "      <td>0.588283</td>\n",
              "      <td>0.277547</td>\n",
              "      <td>0.502170</td>\n",
              "      <td>0.270517</td>\n",
              "      <td>0.334348</td>\n",
              "      <td>0.548095</td>\n",
              "      <td>0.306747</td>\n",
              "      <td>0.540822</td>\n",
              "      <td>0.511380</td>\n",
              "      <td>0.566677</td>\n",
              "      <td>0.778822</td>\n",
              "      <td>0.415356</td>\n",
              "      <td>0.319886</td>\n",
              "      <td>0.369188</td>\n",
              "      <td>0.388345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CAR</th>\n",
              "      <td>0.441895</td>\n",
              "      <td>0.696436</td>\n",
              "      <td>0.383036</td>\n",
              "      <td>0.625011</td>\n",
              "      <td>0.350579</td>\n",
              "      <td>0.521256</td>\n",
              "      <td>0.663138</td>\n",
              "      <td>0.415131</td>\n",
              "      <td>0.518525</td>\n",
              "      <td>0.475220</td>\n",
              "      <td>0.677747</td>\n",
              "      <td>0.778146</td>\n",
              "      <td>0.658222</td>\n",
              "      <td>0.572161</td>\n",
              "      <td>0.643531</td>\n",
              "      <td>0.368109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BOS</th>\n",
              "      <td>0.477872</td>\n",
              "      <td>0.653939</td>\n",
              "      <td>0.510943</td>\n",
              "      <td>0.497905</td>\n",
              "      <td>0.389014</td>\n",
              "      <td>0.610540</td>\n",
              "      <td>0.488804</td>\n",
              "      <td>0.497327</td>\n",
              "      <td>0.533017</td>\n",
              "      <td>0.511563</td>\n",
              "      <td>0.568257</td>\n",
              "      <td>0.834699</td>\n",
              "      <td>0.375159</td>\n",
              "      <td>0.537820</td>\n",
              "      <td>0.493645</td>\n",
              "      <td>0.487770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NYR</th>\n",
              "      <td>0.518318</td>\n",
              "      <td>0.699247</td>\n",
              "      <td>0.469650</td>\n",
              "      <td>0.557725</td>\n",
              "      <td>0.343204</td>\n",
              "      <td>0.647734</td>\n",
              "      <td>0.663303</td>\n",
              "      <td>0.583255</td>\n",
              "      <td>0.591405</td>\n",
              "      <td>0.615081</td>\n",
              "      <td>0.663636</td>\n",
              "      <td>0.858821</td>\n",
              "      <td>0.586611</td>\n",
              "      <td>0.543273</td>\n",
              "      <td>0.575309</td>\n",
              "      <td>0.532411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PIT</th>\n",
              "      <td>0.603644</td>\n",
              "      <td>0.597359</td>\n",
              "      <td>0.559631</td>\n",
              "      <td>0.525699</td>\n",
              "      <td>0.513162</td>\n",
              "      <td>0.601164</td>\n",
              "      <td>0.444848</td>\n",
              "      <td>0.575932</td>\n",
              "      <td>0.631340</td>\n",
              "      <td>0.585186</td>\n",
              "      <td>0.612427</td>\n",
              "      <td>0.880872</td>\n",
              "      <td>0.681734</td>\n",
              "      <td>0.646029</td>\n",
              "      <td>0.544721</td>\n",
              "      <td>0.557745</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd0176d9-777b-4407-b78d-f158a5c655ac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd0176d9-777b-4407-b78d-f158a5c655ac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd0176d9-777b-4407-b78d-f158a5c655ac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "COL = np.zeros(4)\n",
        "NSH = np.zeros(4)\n",
        "MIN = np.zeros(4)\n",
        "STL = np.zeros(4)\n",
        "CGY = np.zeros(4)\n",
        "DAL = np.zeros(4)\n",
        "EDM = np.zeros(4)\n",
        "LAK = np.zeros(4)\n",
        "FLA = np.zeros(4)\n",
        "WSH = np.zeros(4)\n",
        "TOR = np.zeros(4)\n",
        "TBL = np.zeros(4)\n",
        "CAR = np.zeros(4)\n",
        "BOS = np.zeros(4)\n",
        "NYR = np.zeros(4)\n",
        "PIT = np.zeros(4)"
      ],
      "metadata": {
        "id": "ok8piVZzkS87"
      },
      "id": "ok8piVZzkS87",
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#First round, technically\n",
        "round = 0\n",
        "current_team = 0 #colorado\n",
        "COL[round] = Home_table.loc[TeamList[current_team]].loc[TeamList[current_team + 1]]\n",
        "NSH[round] = funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team + 1]]\n",
        "\n",
        "current_team += 2\n",
        "MIN[round] = Home_table.loc[TeamList[current_team]].loc[TeamList[current_team + 1]]\n",
        "STL[round] = funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team + 1]]\n",
        "\n",
        "current_team += 2\n",
        "CGY[round] = Home_table.loc[TeamList[current_team]].loc[TeamList[current_team + 1]]\n",
        "DAL[round] = funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team + 1]]\n",
        "\n",
        "current_team += 2\n",
        "EDM[round] = Home_table.loc[TeamList[current_team]].loc[TeamList[current_team + 1]]\n",
        "LAK[round] = funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team + 1]]\n",
        "\n",
        "current_team += 2\n",
        "FLA[round] = Home_table.loc[TeamList[current_team]].loc[TeamList[current_team + 1]]\n",
        "WSH[round] = funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team + 1]]\n",
        "\n",
        "current_team += 2\n",
        "TOR[round] = Home_table.loc[TeamList[current_team]].loc[TeamList[current_team + 1]]\n",
        "TBL[round] = funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team + 1]]\n",
        "\n",
        "current_team += 2\n",
        "CAR[round] = Home_table.loc[TeamList[current_team]].loc[TeamList[current_team + 1]]\n",
        "BOS[round] = funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team + 1]]\n",
        "\n",
        "current_team += 2\n",
        "NYR[round] = Home_table.loc[TeamList[current_team]].loc[TeamList[current_team + 1]]\n",
        "PIT[round] = funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team + 1]]"
      ],
      "metadata": {
        "id": "81fGV_EQn0TZ"
      },
      "id": "81fGV_EQn0TZ",
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "What is the probability of winning a 2nd round game?\n",
        "\n",
        "Avalance have an 89% chance of making it to teh 2nd round.\n",
        "\n",
        "There, they have two possibilities: minnesota or st louis.\n",
        "The most probable options is they face st. louis and we calculate that probability.\n",
        "\n",
        "((col vs min) * prob min + (col vs blues) * prob blues) * prob avalance\n",
        "\n",
        "((min vs ave) * prob ave + (min vs wild) * prob wild) * prob min\n",
        "\n",
        "(wild * min) * prob min + (wild vs blues) * prob blues    * prob wild\n",
        "\n",
        "(blues * ave) * prob ave + (blues x wild) * prob wild    * prob blues\n",
        "\n"
      ],
      "metadata": {
        "id": "B38XVno0pW9R"
      },
      "id": "B38XVno0pW9R"
    },
    {
      "cell_type": "code",
      "source": [
        "#Second round probabilities\n",
        "round = 1\n",
        "current_team = 0 #colorado\n",
        "#nevermind, brain too smol for this\n",
        "COL[round] = COL[round - 1]*(Home_table.loc[TeamList[current_team]].loc[TeamList[current_team+2]].values * MIN[round-1] \n",
        "                             + Home_table.loc[TeamList[current_team]].loc[TeamList[current_team+3]].values * STL[round-1])\n",
        "NSH[round] = NSH[round - 1]*(Home_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+2]].values * MIN[round-1] \n",
        "                             + Home_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+3]].values * STL[round-1])\n",
        "MIN[round] = MIN[round - 1]*(funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team+2]].values * COL[round-1] \n",
        "                             + funky_prob_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+2]].values * NSH[round-1])\n",
        "STL[round] = STL[round - 1]*(funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team+3]].values * COL[round-1] \n",
        "                             + funky_prob_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+3]].values * NSH[round-1])\n",
        "current_team += 4\n",
        "CGY[round] = CGY[round - 1]*(Home_table.loc[TeamList[current_team]].loc[TeamList[current_team+2]].values *EDM[round-1] \n",
        "                             + Home_table.loc[TeamList[current_team]].loc[TeamList[current_team+3]].values * LAK[round-1])\n",
        "DAL[round] = DAL[round-1]*(Home_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+2]].values * EDM[round-1]\n",
        "                           + Home_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+3]].values * LAK[round-1])\n",
        "EDM[round] = EDM[round-1]*(funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team+2]].values * CGY[round-1]\n",
        "                           + funky_prob_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+2]].values * DAL[round-1])\n",
        "LAK[round] = LAK[round-1]*(funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team+3]].values * CGY[round-1]\n",
        "                           + funky_prob_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+3]].values * DAL[round-1])\n",
        "current_team += 4\n",
        "FLA[round] = FLA[round - 1]*(Home_table.loc[TeamList[current_team]].loc[TeamList[current_team+2]].values *TOR[round-1] \n",
        "                             + Home_table.loc[TeamList[current_team]].loc[TeamList[current_team+3]].values * TBL[round-1])\n",
        "WSH[round] = WSH[round-1]*(Home_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+2]].values * TOR[round-1]\n",
        "                           + Home_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+3]].values * TBL[round-1])\n",
        "TOR[round] = TOR[round-1]*(funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team+2]].values * FLA[round-1]\n",
        "                           + funky_prob_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+2]].values * WSH[round-1])\n",
        "TBL[round] = TBL[round-1]*(funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team+3]].values * FLA[round-1]\n",
        "                           + funky_prob_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+3]].values * WSH[round-1])\n",
        "current_team += 4\n",
        "CAR[round] = CAR[round - 1]*(Home_table.loc[TeamList[current_team]].loc[TeamList[current_team+2]].values *NYR[round-1] \n",
        "                             + Home_table.loc[TeamList[current_team]].loc[TeamList[current_team+3]].values * PIT[round-1])\n",
        "BOS[round] = BOS[round-1]*(Home_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+2]].values * NYR[round-1]\n",
        "                           + Home_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+3]].values * PIT[round-1])\n",
        "NYR[round] = NYR[round-1]*(funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team+2]].values * CAR[round-1]\n",
        "                           + funky_prob_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+2]].values * BOS[round-1])\n",
        "PIT[round] = PIT[round-1]*(funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team+3]].values * CAR[round-1]\n",
        "                           + funky_prob_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+3]].values * BOS[round-1])"
      ],
      "metadata": {
        "id": "ttHc3WgSn0eZ"
      },
      "id": "ttHc3WgSn0eZ",
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "for semis, we have avalance vs 4 possible teams\n",
        "\n",
        "so ave x cal * cal + ave x dal * dal + ave * oil x oil + ave * la * la\n",
        "all times ave\n",
        "\n",
        "\n",
        "put simply: prob(team 1 vs team 2)* prob(team 1) * prob(team 2)"
      ],
      "metadata": {
        "id": "3W7T6GnR1TtK"
      },
      "id": "3W7T6GnR1TtK"
    },
    {
      "cell_type": "code",
      "source": [
        "#Third round probabilities - SEMIFINALS\n",
        "round = 2\n",
        "current_team = 0 #colorado\n",
        "COL[round] = COL[round - 1]*(Home_table.loc[TeamList[current_team]].loc[TeamList[current_team+4]].values * CGY[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team]].loc[TeamList[current_team+5]].values * DAL[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team]].loc[TeamList[current_team+6]].values * EDM[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team]].loc[TeamList[current_team+7]].values * LAK[round-1])\n",
        "NSH[round] = NSH[round - 1]*(Home_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+4]].values * CGY[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+5]].values * DAL[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+6]].values * EDM[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+7]].values * LAK[round-1])\n",
        "MIN[round] = MIN[round - 1]*(Home_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+4]].values * CGY[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+5]].values * DAL[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+6]].values * EDM[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+7]].values * LAK[round-1])\n",
        "STL[round] = STL[round - 1]*(Home_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+4]].values * CGY[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+5]].values * DAL[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+6]].values * EDM[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+7]].values * LAK[round-1])\n",
        "\n",
        "CGY[round] = CGY[round - 1]*(funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team+4]].values * COL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+4]].values * NSH[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+4]].values * MIN[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+4]].values * STL[round-1])\n",
        "DAL[round] = DAL[round-1]*(funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team+5]].values * COL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+5]].values * NSH[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+5]].values * MIN[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+5]].values * STL[round-1])\n",
        "EDM[round] = EDM[round-1]*(funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team+6]].values * COL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+6]].values * NSH[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+6]].values * MIN[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+6]].values * STL[round-1])\n",
        "LAK[round] = LAK[round-1]*(funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team+7]].values * COL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+7]].values * NSH[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+7]].values * MIN[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+7]].values * STL[round-1])\n",
        "current_team += 8\n",
        "FLA[round] = FLA[round - 1]*(Home_table.loc[TeamList[current_team]].loc[TeamList[current_team+4]].values * CAR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team]].loc[TeamList[current_team+5]].values * BOS[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team]].loc[TeamList[current_team+6]].values * NYR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team]].loc[TeamList[current_team+7]].values * PIT[round-1])\n",
        "WSH[round] = WSH[round-1]*(Home_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+4]].values * CAR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+5]].values * BOS[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+6]].values * NYR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+7]].values * PIT[round-1])\n",
        "TOR[round] = TOR[round-1]*(Home_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+4]].values * CAR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+5]].values * BOS[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+6]].values * NYR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+7]].values * PIT[round-1])\n",
        "TBL[round] = TBL[round-1]*(Home_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+4]].values * CAR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+5]].values * BOS[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+6]].values * NYR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+7]].values * PIT[round-1])\n",
        "\n",
        "CAR[round] = CAR[round - 1]*(funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team+4]].values * FLA[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+4]].values * WSH[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+4]].values * TOR[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+4]].values * TBL[round-1])\n",
        "BOS[round] = BOS[round-1]*(funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team+5]].values * FLA[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+5]].values * WSH[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+5]].values * TOR[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+5]].values * TBL[round-1])\n",
        "NYR[round] = NYR[round-1]*(funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team+6]].values * FLA[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+6]].values * WSH[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+6]].values * TOR[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+6]].values * TBL[round-1])\n",
        "PIT[round] = PIT[round-1]*(funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team+7]].values * FLA[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+7]].values * WSH[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+7]].values * TOR[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+7]].values * TBL[round-1])"
      ],
      "metadata": {
        "id": "7FzJ1QjywsGw"
      },
      "id": "7FzJ1QjywsGw",
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fourth round probabilities - FINALS BABY\n",
        "round = 3\n",
        "current_team = 0 #colorado\n",
        "#This is going to suckass\n",
        "COL[round] = COL[round - 1]*(Home_table.loc[TeamList[current_team]].loc[TeamList[current_team+8]].values * FLA[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team]].loc[TeamList[current_team+9]].values * WSH[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team]].loc[TeamList[current_team+10]].values * TOR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team]].loc[TeamList[current_team+11]].values * TBL[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team]].loc[TeamList[current_team+12]].values * CAR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team]].loc[TeamList[current_team+13]].values * BOS[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team]].loc[TeamList[current_team+14]].values * NYR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team]].loc[TeamList[current_team+15]].values * PIT[round-1])\n",
        "\n",
        "NSH[round] = NSH[round - 1]*(Home_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+8]].values * FLA[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+9]].values * WSH[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+10]].values * TOR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+11]].values * TBL[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+12]].values * CAR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+13]].values * BOS[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+14]].values * NYR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+15]].values * PIT[round-1])\n",
        "\n",
        "MIN[round] = MIN[round - 1]*(Home_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+8]].values * FLA[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+9]].values * WSH[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+10]].values * TOR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+11]].values * TBL[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+12]].values * CAR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+13]].values * BOS[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+14]].values * NYR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+15]].values * PIT[round-1])\n",
        "\n",
        "STL[round] = STL[round - 1]*(Home_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+8]].values * FLA[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+9]].values * WSH[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+10]].values * TOR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+11]].values * TBL[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+12]].values * CAR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+13]].values * BOS[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+14]].values * NYR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+15]].values * PIT[round-1])\n",
        "\n",
        "CGY[round] = CGY[round - 1]*(Home_table.loc[TeamList[current_team+4]].loc[TeamList[current_team+8]].values * FLA[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+4]].loc[TeamList[current_team+9]].values * WSH[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+4]].loc[TeamList[current_team+10]].values * TOR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+4]].loc[TeamList[current_team+11]].values * TBL[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+4]].loc[TeamList[current_team+12]].values * CAR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+4]].loc[TeamList[current_team+13]].values * BOS[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+4]].loc[TeamList[current_team+14]].values * NYR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+4]].loc[TeamList[current_team+15]].values * PIT[round-1])\n",
        "\n",
        "DAL[round] = DAL[round-1]*(Home_table.loc[TeamList[current_team+5]].loc[TeamList[current_team+8]].values * FLA[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+5]].loc[TeamList[current_team+9]].values * WSH[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+5]].loc[TeamList[current_team+10]].values * TOR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+5]].loc[TeamList[current_team+11]].values * TBL[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+5]].loc[TeamList[current_team+12]].values * CAR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+5]].loc[TeamList[current_team+13]].values * BOS[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+5]].loc[TeamList[current_team+14]].values * NYR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+5]].loc[TeamList[current_team+15]].values * PIT[round-1])\n",
        "\n",
        "EDM[round] = EDM[round-1]*(Home_table.loc[TeamList[current_team+6]].loc[TeamList[current_team+8]].values * FLA[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+6]].loc[TeamList[current_team+9]].values * WSH[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+6]].loc[TeamList[current_team+10]].values * TOR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+6]].loc[TeamList[current_team+11]].values * TBL[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+6]].loc[TeamList[current_team+12]].values * CAR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+6]].loc[TeamList[current_team+13]].values * BOS[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+6]].loc[TeamList[current_team+14]].values * NYR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+6]].loc[TeamList[current_team+15]].values * PIT[round-1])\n",
        "\n",
        "LAK[round] = LAK[round-1]*(Home_table.loc[TeamList[current_team+7]].loc[TeamList[current_team+8]].values * FLA[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+7]].loc[TeamList[current_team+9]].values * WSH[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+7]].loc[TeamList[current_team+10]].values * TOR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+7]].loc[TeamList[current_team+11]].values * TBL[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+7]].loc[TeamList[current_team+12]].values * CAR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+7]].loc[TeamList[current_team+13]].values * BOS[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+7]].loc[TeamList[current_team+14]].values * NYR[round-1]\n",
        "                             + Home_table.loc[TeamList[current_team+7]].loc[TeamList[current_team+15]].values * PIT[round-1])\n",
        "\n",
        "\n",
        "FLA[round] = FLA[round - 1]*(funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team+8]].values * COL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+8]].values * NSH[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+8]].values * MIN[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+8]].values * STL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+4]].loc[TeamList[current_team+8]].values * CGY[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+5]].loc[TeamList[current_team+8]].values * DAL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+6]].loc[TeamList[current_team+8]].values * EDM[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+7]].loc[TeamList[current_team+8]].values * LAK[round-1])\n",
        "\n",
        "WSH[round] = WSH[round-1]*(funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team+9]].values * COL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+9]].values * NSH[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+9]].values * MIN[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+9]].values * STL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+4]].loc[TeamList[current_team+9]].values * CGY[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+5]].loc[TeamList[current_team+9]].values * DAL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+6]].loc[TeamList[current_team+9]].values * EDM[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+7]].loc[TeamList[current_team+9]].values * LAK[round-1])\n",
        "\n",
        "TOR[round] = TOR[round-1]*(funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team+10]].values * COL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+10]].values * NSH[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+10]].values * MIN[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+10]].values * STL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+4]].loc[TeamList[current_team+10]].values * CGY[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+5]].loc[TeamList[current_team+10]].values * DAL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+6]].loc[TeamList[current_team+10]].values * EDM[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+7]].loc[TeamList[current_team+10]].values * LAK[round-1])\n",
        "\n",
        "TBL[round] = TBL[round-1]*(funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team+11]].values * COL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+11]].values * NSH[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+11]].values * MIN[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+11]].values * STL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+4]].loc[TeamList[current_team+11]].values * CGY[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+5]].loc[TeamList[current_team+11]].values * DAL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+6]].loc[TeamList[current_team+11]].values * EDM[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+7]].loc[TeamList[current_team+11]].values * LAK[round-1])\n",
        "\n",
        "CAR[round] = CAR[round - 1]*(funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team+12]].values * COL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+12]].values * NSH[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+12]].values * MIN[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+12]].values * STL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+4]].loc[TeamList[current_team+12]].values * CGY[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+5]].loc[TeamList[current_team+12]].values * DAL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+6]].loc[TeamList[current_team+12]].values * EDM[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+7]].loc[TeamList[current_team+12]].values * LAK[round-1])\n",
        "\n",
        "BOS[round] = BOS[round-1]*(funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team+13]].values * COL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+13]].values * NSH[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+13]].values * MIN[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+13]].values * STL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+4]].loc[TeamList[current_team+13]].values * CGY[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+5]].loc[TeamList[current_team+13]].values * DAL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+6]].loc[TeamList[current_team+13]].values * EDM[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+7]].loc[TeamList[current_team+13]].values * LAK[round-1])\n",
        "\n",
        "NYR[round] = NYR[round-1]*(funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team+14]].values * COL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+14]].values * NSH[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+14]].values * MIN[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+14]].values * STL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+4]].loc[TeamList[current_team+14]].values * CGY[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+5]].loc[TeamList[current_team+14]].values * DAL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+6]].loc[TeamList[current_team+14]].values * EDM[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+7]].loc[TeamList[current_team+14]].values * LAK[round-1])\n",
        "\n",
        "PIT[round] = PIT[round-1]*(funky_prob_table.loc[TeamList[current_team]].loc[TeamList[current_team+15]].values * COL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+1]].loc[TeamList[current_team+15]].values * NSH[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+2]].loc[TeamList[current_team+15]].values * MIN[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+3]].loc[TeamList[current_team+15]].values * STL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+4]].loc[TeamList[current_team+15]].values * CGY[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+5]].loc[TeamList[current_team+15]].values * DAL[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+6]].loc[TeamList[current_team+15]].values * EDM[round-1]\n",
        "                             + funky_prob_table.loc[TeamList[current_team+7]].loc[TeamList[current_team+15]].values * LAK[round-1])"
      ],
      "metadata": {
        "id": "WADPq1YQ3a_v"
      },
      "id": "WADPq1YQ3a_v",
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('COL',COL)\n",
        "print('NSH',NSH)\n",
        "print('MIN',MIN)\n",
        "print('STL',STL)\n",
        "print('CGY',CGY)\n",
        "print('DAL',DAL)\n",
        "print('EDM',EDM)\n",
        "print('LAK',LAK)\n",
        "print('FLA',FLA)\n",
        "print('WSH',WSH)\n",
        "print('TOR',TOR)\n",
        "print('TBL',TBL)\n",
        "print('CAR',CAR)\n",
        "print('BOS',BOS)\n",
        "print('NYR',NYR)\n",
        "print('PIT',PIT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV60G9dH6Eum",
        "outputId": "bd343e1d-2adc-4efe-9c32-7fc03d12a7ea"
      },
      "id": "rV60G9dH6Eum",
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COL [0.7423531  0.30232783 0.18564556 0.15139025]\n",
            "NSH [0.2576469  0.10494867 0.04160056 0.01355967]\n",
            "MIN [0.22026859 0.1478121  0.12070808 0.09142444]\n",
            "STL [0.77973141 0.44491141 0.21537069 0.14828921]\n",
            "CGY [0.77674478 0.45899328 0.19021447 0.12794395]\n",
            "DAL [0.22325522 0.10321625 0.03642835 0.01555459]\n",
            "EDM [0.20876129 0.12245666 0.02343919 0.01280272]\n",
            "LAK [0.79123871 0.31533381 0.18659311 0.11657114]\n",
            "FLA [0.24410088 0.20668203 0.13528321 0.04661231]\n",
            "WSH [0.75589912 0.4698956  0.29259225 0.0737937 ]\n",
            "TOR [0.99817861 0.32340106 0.20380759 0.05633964]\n",
            "TBL [1.82139092e-03 2.13138345e-05 4.34136463e-06 4.58510825e-08]\n",
            "CAR [0.62044936 0.34082405 0.05500622 0.01075285]\n",
            "BOS [0.37955064 0.18391975 0.07408879 0.02227936]\n",
            "NYR [0.61537844 0.19609612 0.06279189 0.02150891]\n",
            "PIT [0.38462156 0.27916009 0.17642571 0.09117721]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#np.savetxt(\"AllMatchups.csv\", X_pred, delimiter=\",\")"
      ],
      "metadata": {
        "id": "CMDD7rw2MSc-"
      },
      "id": "CMDD7rw2MSc-",
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Final_probs = np.vstack((COL, NSH, MIN, STL, CGY, DAL, EDM, LAK, FLA, WSH, TOR, TBL, CAR, BOS, NYR, PIT))\n",
        "Final_probs[:,3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK6wK2Q86ZPE",
        "outputId": "103dc64e-3a94-4b6b-c5bc-673cdc332573"
      },
      "id": "fK6wK2Q86ZPE",
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.51390252e-01, 1.35596732e-02, 9.14244412e-02, 1.48289206e-01,\n",
              "       1.27943947e-01, 1.55545929e-02, 1.28027225e-02, 1.16571142e-01,\n",
              "       4.66123056e-02, 7.37936976e-02, 5.63396445e-02, 4.58510825e-08,\n",
              "       1.07528504e-02, 2.22793617e-02, 2.15089061e-02, 9.11772118e-02])"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The \", TeamList[np.argmax(Final_probs[:,3])], \"are going to win the Stanley Cup with \", Final_probs[:,3].max()*100,\"% probability\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sPovZDS67k0",
        "outputId": "4f7e271d-2327-4099-c07e-879240f5dd16"
      },
      "id": "2sPovZDS67k0",
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The  COL are going to win the Stanley Cup with  15.139025210212562 % probability\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "NN_log_rf_ada_models.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}