{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c11e1fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#allows drawing digrams in jupyeter notebooks\n",
    "%matplotlib inline\n",
    "#loading tensorboard\n",
    "%load_ext tensorboard\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#specific tensorflow libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers, metrics\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ddf67cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "276c70cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23f3f563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30b6b262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1948e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Test_XY_normalize_PCA(TrainX, TrainY, PCA_n = None):\n",
    "    \n",
    "    # normalize data\n",
    "    scaler_new = StandardScaler()\n",
    "    scaler_new.fit(TrainX)\n",
    "    X_train_scale = scaler_new.transform(TrainX)\n",
    "    print(f'X shape {X_train_scale.shape}')\n",
    "    \n",
    "    if PCA_n != None:\n",
    "        # dimension reduction\n",
    "        TrainX_PCA = Train_Test_XY_PCA(X_train_scale, PCA_n = PCA_n)\n",
    "        print(f'X shape {TrainX_PCA.shape}')\n",
    "    \n",
    "        # normalize again\n",
    "        scaler_new = StandardScaler()\n",
    "        scaler_new.fit(TrainX_PCA)\n",
    "        X_train_scale = scaler_new.transform(TrainX_PCA)\n",
    "        \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train_scale,TrainY,\n",
    "                                                       test_size=.2,\n",
    "                                                       shuffle=True,\n",
    "                                                       random_state=2020,\n",
    "                                                       stratify=TrainY)\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2f024c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as Kb\n",
    "\n",
    "# Write a custom loss function\n",
    "def custom_loss(y_true, y_pred):\n",
    "    binary_crossentropy = Kb.mean(Kb.binary_crossentropy(y_true, y_pred), axis = -1)\n",
    "    prob_constraint = Kb.square(Kb.sum(y_pred, axis = -1)\n",
    "                                - Kb.sum(y_true, axis = -1))\n",
    "\n",
    "    return(binary_crossentropy+prob_constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b429cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_TF_model(structure, ipt_dim, learning_rate=0.01):\n",
    "    model=Sequential()\n",
    "\n",
    "    model.add(layers.Dense(structure[0], input_shape=(ipt_dim,), activation='relu'))\n",
    "    \n",
    "    for i in range(len(structure)-1):\n",
    "        model.add(layers.Dense(structure[i+1], activation='relu'))\n",
    "        \n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # opt = optimizers.SGD(learning_rate=0.01)\n",
    "    # opt = optimizers.Adam(learning_rate=0.1)\n",
    "    opt = optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "    # model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    # model.compile(loss=custom_loss, optimizer=opt)\n",
    "    # model.compile(loss='huber', optimizer=opt)\n",
    "    # model.compile(loss='binary_focal_crossentropy', optimizer=opt)\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60099a37",
   "metadata": {},
   "source": [
    "# simple NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc6ebed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# sns.pairplot(data=tm_players,\n",
    "#              y_vars = ['Winner'],\n",
    "#              x_vars = see_column2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d674d4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Winner' 'F_home_assists' 'F_home_goals' 'F_home_pim' 'F_home_shots'\n",
      " 'F_home_blocked' 'F_home_pm' 'D_home_assists' 'D_home_goals' 'D_home_pim'\n",
      " 'D_home_shots' 'D_home_blocked' 'D_home_hits' 'D_home_pm' 'G_home_GAA'\n",
      " 'F_away_assists' 'F_away_goals' 'F_away_pim' 'F_away_shots'\n",
      " 'F_away_blocked' 'F_away_hits' 'F_away_pm' 'D_away_assists'\n",
      " 'D_away_goals' 'D_away_pim' 'D_away_shots' 'D_away_blocked' 'D_away_hits'\n",
      " 'D_away_pm' 'G_away_GAA' 'F_home_hits']\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "# see_column = np.array(['Rk', 'AvAge', 'GP', 'W', 'L', 'OL', 'PTS', 'PTS%',\n",
    "#        'GF', 'GA', 'SOW', 'SOL', 'SRS', 'SOS', 'GF/G', 'GA/G', 'PP', 'PPO',\n",
    "#        'PP%', 'PPA', 'PPOA', 'PK%', 'SH', 'SHA', 'PIM/G', 'oPIM/G', 'S', 'S%',\n",
    "#        'SA', 'SV%', 'SO', 'Hits', 'Hits/60', 'BkS', 'BkS/60', 'GvA', 'GvA/60',\n",
    "#        'TkA', 'TkA/60', 'ENG', 'MsS', '5v5 TOI/GP', 'SAT%', 'Playoffs%',\n",
    "#        'Playoffs', 'WonCup', 'TA/GA'])\n",
    "\n",
    "see_column = np.array(['PTS', 'W','L', 'GF', 'GA', 'SRS', \n",
    "                                  'SOS', 'PK%', 'S%', 'SV%', 'SAT%', \n",
    "                                  'MsS', 'TA/GA'])\n",
    "# see_column = np.array(['W', 'L', 'GA', 'SAT%', 'TA/GA'])\n",
    "\n",
    "see_column2 = np.array(['Winner',\n",
    "                       'F_home_assists', 'F_home_goals', 'F_home_pim', 'F_home_shots',\n",
    "                       'F_home_blocked', 'F_home_pm', 'D_home_assists', 'D_home_goals',\n",
    "                       'D_home_pim', 'D_home_shots', 'D_home_blocked', 'D_home_hits',\n",
    "                       'D_home_pm', 'G_home_GAA', 'F_away_assists', 'F_away_goals',\n",
    "                       'F_away_pim', 'F_away_shots', 'F_away_blocked', 'F_away_hits',\n",
    "                       'F_away_pm', 'D_away_assists', 'D_away_goals', 'D_away_pim',\n",
    "                       'D_away_shots', 'D_away_blocked', 'D_away_hits', 'D_away_pm',\n",
    "                       'G_away_GAA', 'F_home_hits'])\n",
    "\n",
    "\n",
    "column_home = np.array([i+'_H' for i in see_column])\n",
    "column_away = np.array([i+'_A' for i in see_column])\n",
    "\n",
    "column_name = np.concatenate((column_home,column_away))\n",
    "\n",
    "column_name = np.concatenate((see_column2,column_name))\n",
    "#  column_name = np.concatenate((column_name,['class'])) # Winner is the class\n",
    "\n",
    "# ## only consider tm data\n",
    "# column_home = np.array([i+'_H' for i in see_column])\n",
    "# column_away = np.array([i+'_A' for i in see_column])\n",
    "# column_name = np.concatenate((column_home,column_away))\n",
    "# column_name = np.concatenate((['Winner'],column_name)) # Winner is the class\n",
    "\n",
    "## only consider players data\n",
    "column_name = see_column2\n",
    "\n",
    "print(column_name)\n",
    "print(len(column_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4284648c",
   "metadata": {},
   "source": [
    "#### Train NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51ce4fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Winner</th>\n",
       "      <th>F_home_assists</th>\n",
       "      <th>F_home_goals</th>\n",
       "      <th>F_home_pim</th>\n",
       "      <th>F_home_shots</th>\n",
       "      <th>F_home_blocked</th>\n",
       "      <th>F_home_pm</th>\n",
       "      <th>D_home_assists</th>\n",
       "      <th>D_home_goals</th>\n",
       "      <th>D_home_pim</th>\n",
       "      <th>...</th>\n",
       "      <th>F_away_pm</th>\n",
       "      <th>D_away_assists</th>\n",
       "      <th>D_away_goals</th>\n",
       "      <th>D_away_pim</th>\n",
       "      <th>D_away_shots</th>\n",
       "      <th>D_away_blocked</th>\n",
       "      <th>D_away_hits</th>\n",
       "      <th>D_away_pm</th>\n",
       "      <th>G_away_GAA</th>\n",
       "      <th>F_home_hits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6231</th>\n",
       "      <td>1</td>\n",
       "      <td>0.993978</td>\n",
       "      <td>0.769472</td>\n",
       "      <td>1.629385</td>\n",
       "      <td>7.909387</td>\n",
       "      <td>1.409462</td>\n",
       "      <td>-0.055844</td>\n",
       "      <td>0.67628</td>\n",
       "      <td>0.197776</td>\n",
       "      <td>1.864927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177063</td>\n",
       "      <td>0.929502</td>\n",
       "      <td>0.187523</td>\n",
       "      <td>1.313032</td>\n",
       "      <td>4.308478</td>\n",
       "      <td>4.452491</td>\n",
       "      <td>2.518393</td>\n",
       "      <td>0.20302</td>\n",
       "      <td>2.365582</td>\n",
       "      <td>3.977412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Winner  F_home_assists  F_home_goals  F_home_pim  F_home_shots  \\\n",
       "6231       1        0.993978      0.769472    1.629385      7.909387   \n",
       "\n",
       "      F_home_blocked  F_home_pm  D_home_assists  D_home_goals  D_home_pim  \\\n",
       "6231        1.409462  -0.055844         0.67628      0.197776    1.864927   \n",
       "\n",
       "      ...  F_away_pm  D_away_assists  D_away_goals  D_away_pim  D_away_shots  \\\n",
       "6231  ...   0.177063        0.929502      0.187523    1.313032      4.308478   \n",
       "\n",
       "      D_away_blocked  D_away_hits  D_away_pm  G_away_GAA  F_home_hits  \n",
       "6231        4.452491     2.518393    0.20302    2.365582     3.977412  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm_players = pd.read_csv('tm_player_stats_2005_2021.csv')\n",
    "\n",
    "tm_players[column_name].sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68d4295a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4528204835114591\n"
     ]
    }
   ],
   "source": [
    "# Traindf_diff = pd.DataFrame(data = Traindf[column_home].to_numpy() \n",
    "#                                     - Traindf[column_away].to_numpy(), \n",
    "#                             columns = see_column)\n",
    "\n",
    "Traindf = tm_players[column_name]\n",
    "TrainX_array = Traindf[column_name[1:]].to_numpy()\n",
    "TrainY_array = Traindf[column_name[0]].to_numpy()\n",
    "print(sum(TrainY_array)/len(TrainY_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe19763c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape (17497, 30)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = Train_Test_XY_normalize_PCA(TrainX_array, \n",
    "                                                               TrainY_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6d38592",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 20)                620       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 30)                330       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,191\n",
      "Trainable params: 1,191\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.6633 - accuracy: 0.5967 - val_loss: 0.6558 - val_accuracy: 0.6089\n",
      "Epoch 2/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6532 - accuracy: 0.6183 - val_loss: 0.6540 - val_accuracy: 0.6071\n",
      "Epoch 3/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6498 - accuracy: 0.6190 - val_loss: 0.6540 - val_accuracy: 0.6079\n",
      "Epoch 4/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.6218 - val_loss: 0.6531 - val_accuracy: 0.6046\n",
      "Epoch 5/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6245 - val_loss: 0.6531 - val_accuracy: 0.6150\n",
      "Epoch 6/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6451 - accuracy: 0.6265 - val_loss: 0.6593 - val_accuracy: 0.6018\n",
      "Epoch 7/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6446 - accuracy: 0.6269 - val_loss: 0.6555 - val_accuracy: 0.6093\n",
      "Epoch 8/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6432 - accuracy: 0.6282 - val_loss: 0.6561 - val_accuracy: 0.6054\n",
      "Epoch 9/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6419 - accuracy: 0.6322 - val_loss: 0.6565 - val_accuracy: 0.5971\n",
      "Epoch 10/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.6404 - accuracy: 0.6344 - val_loss: 0.6625 - val_accuracy: 0.5993\n",
      "Epoch 11/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6388 - accuracy: 0.6385 - val_loss: 0.6610 - val_accuracy: 0.6039\n",
      "Epoch 12/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.6379 - accuracy: 0.6357 - val_loss: 0.6637 - val_accuracy: 0.6007\n",
      "Epoch 13/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6366 - accuracy: 0.6346 - val_loss: 0.6663 - val_accuracy: 0.5971\n",
      "Epoch 14/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6356 - accuracy: 0.6365 - val_loss: 0.6607 - val_accuracy: 0.5996\n",
      "Epoch 15/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6344 - accuracy: 0.6427 - val_loss: 0.6650 - val_accuracy: 0.5968\n",
      "Epoch 16/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.6393 - val_loss: 0.6687 - val_accuracy: 0.6014\n",
      "Epoch 17/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6309 - accuracy: 0.6466 - val_loss: 0.6683 - val_accuracy: 0.6032\n",
      "Epoch 18/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6288 - accuracy: 0.6450 - val_loss: 0.6707 - val_accuracy: 0.5993\n",
      "Epoch 19/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.6281 - accuracy: 0.6455 - val_loss: 0.6736 - val_accuracy: 0.6000\n",
      "Epoch 20/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6275 - accuracy: 0.6473 - val_loss: 0.6660 - val_accuracy: 0.6000\n",
      "Epoch 21/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6259 - accuracy: 0.6483 - val_loss: 0.6766 - val_accuracy: 0.6004\n",
      "Epoch 22/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6251 - accuracy: 0.6520 - val_loss: 0.6736 - val_accuracy: 0.5975\n",
      "Epoch 23/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.6534 - val_loss: 0.6802 - val_accuracy: 0.5921\n",
      "Epoch 24/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.6232 - accuracy: 0.6479 - val_loss: 0.6786 - val_accuracy: 0.5950\n",
      "Epoch 25/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.6220 - accuracy: 0.6512 - val_loss: 0.6855 - val_accuracy: 0.5943\n",
      "Epoch 26/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.6209 - accuracy: 0.6559 - val_loss: 0.6760 - val_accuracy: 0.5889\n",
      "Epoch 27/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6156 - accuracy: 0.6571 - val_loss: 0.6978 - val_accuracy: 0.5946\n",
      "Epoch 28/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6151 - accuracy: 0.6571 - val_loss: 0.6854 - val_accuracy: 0.5911\n",
      "Epoch 29/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.6554 - val_loss: 0.6893 - val_accuracy: 0.5907\n",
      "Epoch 30/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6144 - accuracy: 0.6593 - val_loss: 0.7084 - val_accuracy: 0.5929\n",
      "Epoch 31/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6127 - accuracy: 0.6610 - val_loss: 0.6967 - val_accuracy: 0.5968\n",
      "Epoch 32/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6126 - accuracy: 0.6628 - val_loss: 0.6941 - val_accuracy: 0.5968\n",
      "Epoch 33/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6099 - accuracy: 0.6664 - val_loss: 0.6903 - val_accuracy: 0.5789\n",
      "Epoch 34/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.6097 - accuracy: 0.6604 - val_loss: 0.6976 - val_accuracy: 0.5857\n",
      "Epoch 35/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.6675 - val_loss: 0.7133 - val_accuracy: 0.5925\n",
      "Epoch 36/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.6688 - val_loss: 0.7000 - val_accuracy: 0.6004\n",
      "Epoch 37/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.6714 - val_loss: 0.7135 - val_accuracy: 0.5982\n",
      "Epoch 38/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6036 - accuracy: 0.6695 - val_loss: 0.6966 - val_accuracy: 0.5904\n",
      "Epoch 39/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6029 - accuracy: 0.6706 - val_loss: 0.7057 - val_accuracy: 0.5921\n",
      "Epoch 40/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5997 - accuracy: 0.6747 - val_loss: 0.7181 - val_accuracy: 0.5921\n",
      "Epoch 41/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6027 - accuracy: 0.6712 - val_loss: 0.7139 - val_accuracy: 0.5950\n",
      "Epoch 42/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.6006 - accuracy: 0.6706 - val_loss: 0.7191 - val_accuracy: 0.5946\n",
      "Epoch 43/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.6002 - accuracy: 0.6730 - val_loss: 0.7209 - val_accuracy: 0.5954\n",
      "Epoch 44/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5982 - accuracy: 0.6745 - val_loss: 0.7201 - val_accuracy: 0.5811\n",
      "Epoch 45/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5981 - accuracy: 0.6764 - val_loss: 0.7215 - val_accuracy: 0.5825\n",
      "Epoch 46/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5991 - accuracy: 0.6757 - val_loss: 0.7145 - val_accuracy: 0.5882\n",
      "Epoch 47/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.6761 - val_loss: 0.7183 - val_accuracy: 0.5879\n",
      "Epoch 48/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.6813 - val_loss: 0.7146 - val_accuracy: 0.5814\n",
      "Epoch 49/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5920 - accuracy: 0.6854 - val_loss: 0.7170 - val_accuracy: 0.5868\n",
      "Epoch 50/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.6828 - val_loss: 0.7275 - val_accuracy: 0.5868\n",
      "Epoch 51/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.6782 - val_loss: 0.7390 - val_accuracy: 0.5786\n",
      "Epoch 52/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5929 - accuracy: 0.6815 - val_loss: 0.7287 - val_accuracy: 0.5904\n",
      "Epoch 53/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5922 - accuracy: 0.6786 - val_loss: 0.7545 - val_accuracy: 0.5818\n",
      "Epoch 54/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5918 - accuracy: 0.6830 - val_loss: 0.7268 - val_accuracy: 0.5871\n",
      "Epoch 55/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5883 - accuracy: 0.6849 - val_loss: 0.7419 - val_accuracy: 0.5757\n",
      "Epoch 56/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.6865 - val_loss: 0.7399 - val_accuracy: 0.5671\n",
      "Epoch 57/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5886 - accuracy: 0.6885 - val_loss: 0.7464 - val_accuracy: 0.5800\n",
      "Epoch 58/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5898 - accuracy: 0.6811 - val_loss: 0.7616 - val_accuracy: 0.5775\n",
      "Epoch 59/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5875 - accuracy: 0.6891 - val_loss: 0.7475 - val_accuracy: 0.5807\n",
      "Epoch 60/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5888 - accuracy: 0.6852 - val_loss: 0.7511 - val_accuracy: 0.5786\n",
      "Epoch 61/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5858 - accuracy: 0.6880 - val_loss: 0.7607 - val_accuracy: 0.5829\n",
      "Epoch 62/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5843 - accuracy: 0.6888 - val_loss: 0.7840 - val_accuracy: 0.5718\n",
      "Epoch 63/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5859 - accuracy: 0.6906 - val_loss: 0.7584 - val_accuracy: 0.5821\n",
      "Epoch 64/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5864 - accuracy: 0.6905 - val_loss: 0.7652 - val_accuracy: 0.5704\n",
      "Epoch 65/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.6904 - val_loss: 0.7695 - val_accuracy: 0.5757\n",
      "Epoch 66/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.6920 - val_loss: 0.7750 - val_accuracy: 0.5825\n",
      "Epoch 67/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.6899 - val_loss: 0.7609 - val_accuracy: 0.5671\n",
      "Epoch 68/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5815 - accuracy: 0.6877 - val_loss: 0.7845 - val_accuracy: 0.5704\n",
      "Epoch 69/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.6891 - val_loss: 0.7736 - val_accuracy: 0.5764\n",
      "Epoch 70/300\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.5822 - accuracy: 0.6927 - val_loss: 0.7778 - val_accuracy: 0.5743\n",
      "Epoch 71/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.6888 - val_loss: 0.7405 - val_accuracy: 0.5761\n",
      "Epoch 72/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.6930 - val_loss: 0.7845 - val_accuracy: 0.5743\n",
      "Epoch 73/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5820 - accuracy: 0.6904 - val_loss: 0.7838 - val_accuracy: 0.5757\n",
      "Epoch 74/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.6954 - val_loss: 0.7864 - val_accuracy: 0.5711\n",
      "Epoch 75/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.6927 - val_loss: 0.7787 - val_accuracy: 0.5714\n",
      "Epoch 76/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.6940 - val_loss: 0.7488 - val_accuracy: 0.5743\n",
      "Epoch 77/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5800 - accuracy: 0.6912 - val_loss: 0.7758 - val_accuracy: 0.5804\n",
      "Epoch 78/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.6929 - val_loss: 0.7777 - val_accuracy: 0.5775\n",
      "Epoch 79/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.6996 - val_loss: 0.7634 - val_accuracy: 0.5689\n",
      "Epoch 80/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.6936 - val_loss: 0.7961 - val_accuracy: 0.5761\n",
      "Epoch 81/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.6938 - val_loss: 0.7952 - val_accuracy: 0.5654\n",
      "Epoch 82/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.6922 - val_loss: 0.7859 - val_accuracy: 0.5743\n",
      "Epoch 83/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5763 - accuracy: 0.6979 - val_loss: 0.7977 - val_accuracy: 0.5661\n",
      "Epoch 84/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.6942 - val_loss: 0.8230 - val_accuracy: 0.5679\n",
      "Epoch 85/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5771 - accuracy: 0.6968 - val_loss: 0.7842 - val_accuracy: 0.5693\n",
      "Epoch 86/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5748 - accuracy: 0.6978 - val_loss: 0.7964 - val_accuracy: 0.5704\n",
      "Epoch 87/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5758 - accuracy: 0.6961 - val_loss: 0.8337 - val_accuracy: 0.5736\n",
      "Epoch 88/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5753 - accuracy: 0.6980 - val_loss: 0.8009 - val_accuracy: 0.5754\n",
      "Epoch 89/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.6961 - val_loss: 0.7968 - val_accuracy: 0.5732\n",
      "Epoch 90/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.6981 - val_loss: 0.7853 - val_accuracy: 0.5657\n",
      "Epoch 91/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.6967 - val_loss: 0.8068 - val_accuracy: 0.5689\n",
      "Epoch 92/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5753 - accuracy: 0.6962 - val_loss: 0.8005 - val_accuracy: 0.5650\n",
      "Epoch 93/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5737 - accuracy: 0.6982 - val_loss: 0.8110 - val_accuracy: 0.5743\n",
      "Epoch 94/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5760 - accuracy: 0.6970 - val_loss: 0.7999 - val_accuracy: 0.5718\n",
      "Epoch 95/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7023 - val_loss: 0.8389 - val_accuracy: 0.5754\n",
      "Epoch 96/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5768 - accuracy: 0.6974 - val_loss: 0.8169 - val_accuracy: 0.5754\n",
      "Epoch 97/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5746 - accuracy: 0.6973 - val_loss: 0.8198 - val_accuracy: 0.5714\n",
      "Epoch 98/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7013 - val_loss: 0.8579 - val_accuracy: 0.5746\n",
      "Epoch 99/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.7023 - val_loss: 0.8307 - val_accuracy: 0.5718\n",
      "Epoch 100/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5705 - accuracy: 0.7013 - val_loss: 0.8144 - val_accuracy: 0.5711\n",
      "Epoch 101/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.7034 - val_loss: 0.8294 - val_accuracy: 0.5643\n",
      "Epoch 102/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.6997 - val_loss: 0.7935 - val_accuracy: 0.5686\n",
      "Epoch 103/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.7024 - val_loss: 0.8179 - val_accuracy: 0.5729\n",
      "Epoch 104/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.7037 - val_loss: 0.7959 - val_accuracy: 0.5571\n",
      "Epoch 105/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5748 - accuracy: 0.6992 - val_loss: 0.8068 - val_accuracy: 0.5693\n",
      "Epoch 106/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.7030 - val_loss: 0.8430 - val_accuracy: 0.5721\n",
      "Epoch 107/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5707 - accuracy: 0.7037 - val_loss: 0.8580 - val_accuracy: 0.5661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.7013 - val_loss: 0.7729 - val_accuracy: 0.5657\n",
      "Epoch 109/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.7073 - val_loss: 0.8310 - val_accuracy: 0.5736\n",
      "Epoch 110/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7072 - val_loss: 0.8482 - val_accuracy: 0.5693\n",
      "Epoch 111/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.7072 - val_loss: 0.8412 - val_accuracy: 0.5661\n",
      "Epoch 112/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7057 - val_loss: 0.8165 - val_accuracy: 0.5754\n",
      "Epoch 113/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.7053 - val_loss: 0.8339 - val_accuracy: 0.5743\n",
      "Epoch 114/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.7036 - val_loss: 0.8377 - val_accuracy: 0.5743\n",
      "Epoch 115/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5692 - accuracy: 0.7088 - val_loss: 0.8474 - val_accuracy: 0.5693\n",
      "Epoch 116/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.7030 - val_loss: 0.8415 - val_accuracy: 0.5679\n",
      "Epoch 117/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.7040 - val_loss: 0.8474 - val_accuracy: 0.5696\n",
      "Epoch 118/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5640 - accuracy: 0.7059 - val_loss: 0.8441 - val_accuracy: 0.5736\n",
      "Epoch 119/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5731 - accuracy: 0.7028 - val_loss: 0.8192 - val_accuracy: 0.5714\n",
      "Epoch 120/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.7022 - val_loss: 0.8288 - val_accuracy: 0.5689\n",
      "Epoch 121/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7032 - val_loss: 0.8313 - val_accuracy: 0.5639\n",
      "Epoch 122/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5640 - accuracy: 0.7082 - val_loss: 0.8379 - val_accuracy: 0.5632\n",
      "Epoch 123/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5642 - accuracy: 0.7093 - val_loss: 0.8530 - val_accuracy: 0.5736\n",
      "Epoch 124/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5629 - accuracy: 0.7093 - val_loss: 0.8494 - val_accuracy: 0.5646\n",
      "Epoch 125/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7097 - val_loss: 0.8441 - val_accuracy: 0.5639\n",
      "Epoch 126/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5632 - accuracy: 0.7145 - val_loss: 0.8348 - val_accuracy: 0.5668\n",
      "Epoch 127/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5650 - accuracy: 0.7090 - val_loss: 0.8312 - val_accuracy: 0.5696\n",
      "Epoch 128/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7086 - val_loss: 0.8612 - val_accuracy: 0.5604\n",
      "Epoch 129/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5646 - accuracy: 0.7056 - val_loss: 0.8654 - val_accuracy: 0.5743\n",
      "Epoch 130/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7022 - val_loss: 0.8390 - val_accuracy: 0.5764\n",
      "Epoch 131/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5707 - accuracy: 0.7034 - val_loss: 0.8441 - val_accuracy: 0.5657\n",
      "Epoch 132/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.7111 - val_loss: 0.8596 - val_accuracy: 0.5675\n",
      "Epoch 133/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.7104 - val_loss: 0.8849 - val_accuracy: 0.5721\n",
      "Epoch 134/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.7139 - val_loss: 0.8476 - val_accuracy: 0.5786\n",
      "Epoch 135/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5634 - accuracy: 0.7109 - val_loss: 0.8482 - val_accuracy: 0.5718\n",
      "Epoch 136/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5592 - accuracy: 0.7148 - val_loss: 0.8975 - val_accuracy: 0.5643\n",
      "Epoch 137/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.7056 - val_loss: 0.8804 - val_accuracy: 0.5714\n",
      "Epoch 138/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5598 - accuracy: 0.7142 - val_loss: 0.8626 - val_accuracy: 0.5679\n",
      "Epoch 139/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7087 - val_loss: 0.8899 - val_accuracy: 0.5682\n",
      "Epoch 140/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.7084 - val_loss: 0.8508 - val_accuracy: 0.5693\n",
      "Epoch 141/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5620 - accuracy: 0.7105 - val_loss: 0.8399 - val_accuracy: 0.5650\n",
      "Epoch 142/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5624 - accuracy: 0.7109 - val_loss: 0.8598 - val_accuracy: 0.5707\n",
      "Epoch 143/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.7114 - val_loss: 0.8685 - val_accuracy: 0.5668\n",
      "Epoch 144/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.7095 - val_loss: 0.8654 - val_accuracy: 0.5746\n",
      "Epoch 145/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.7139 - val_loss: 0.8806 - val_accuracy: 0.5657\n",
      "Epoch 146/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7141 - val_loss: 0.8754 - val_accuracy: 0.5675\n",
      "Epoch 147/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5620 - accuracy: 0.7122 - val_loss: 0.8573 - val_accuracy: 0.5579\n",
      "Epoch 148/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7135 - val_loss: 0.8901 - val_accuracy: 0.5661\n",
      "Epoch 149/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5611 - accuracy: 0.7133 - val_loss: 0.8783 - val_accuracy: 0.5729\n",
      "Epoch 150/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7115 - val_loss: 0.8797 - val_accuracy: 0.5693\n",
      "Epoch 151/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5628 - accuracy: 0.7112 - val_loss: 0.8520 - val_accuracy: 0.5643\n",
      "Epoch 152/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5640 - accuracy: 0.7088 - val_loss: 0.8845 - val_accuracy: 0.5721\n",
      "Epoch 153/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7131 - val_loss: 0.8805 - val_accuracy: 0.5657\n",
      "Epoch 154/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5609 - accuracy: 0.7122 - val_loss: 0.8719 - val_accuracy: 0.5657\n",
      "Epoch 155/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7155 - val_loss: 0.8944 - val_accuracy: 0.5686\n",
      "Epoch 156/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7097 - val_loss: 0.8741 - val_accuracy: 0.5654\n",
      "Epoch 157/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7123 - val_loss: 0.8752 - val_accuracy: 0.5668\n",
      "Epoch 158/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7142 - val_loss: 0.8693 - val_accuracy: 0.5707\n",
      "Epoch 159/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5620 - accuracy: 0.7142 - val_loss: 0.8713 - val_accuracy: 0.5757\n",
      "Epoch 160/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7136 - val_loss: 0.8729 - val_accuracy: 0.5689\n",
      "Epoch 161/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7163 - val_loss: 0.9003 - val_accuracy: 0.5725\n",
      "Epoch 162/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.7160 - val_loss: 0.8774 - val_accuracy: 0.5650\n",
      "Epoch 163/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7172 - val_loss: 0.9041 - val_accuracy: 0.5604\n",
      "Epoch 164/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7169 - val_loss: 0.8879 - val_accuracy: 0.5654\n",
      "Epoch 165/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7132 - val_loss: 0.8893 - val_accuracy: 0.5686\n",
      "Epoch 166/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.7130 - val_loss: 0.8665 - val_accuracy: 0.5725\n",
      "Epoch 167/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.7158 - val_loss: 0.9033 - val_accuracy: 0.5714\n",
      "Epoch 168/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7168 - val_loss: 0.9512 - val_accuracy: 0.5693\n",
      "Epoch 169/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7154 - val_loss: 0.9195 - val_accuracy: 0.5696\n",
      "Epoch 170/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.7143 - val_loss: 0.9190 - val_accuracy: 0.5686\n",
      "Epoch 171/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7128 - val_loss: 0.9423 - val_accuracy: 0.5621\n",
      "Epoch 172/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.7160 - val_loss: 0.9204 - val_accuracy: 0.5671\n",
      "Epoch 173/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5553 - accuracy: 0.7185 - val_loss: 0.9100 - val_accuracy: 0.5693\n",
      "Epoch 174/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5591 - accuracy: 0.7145 - val_loss: 0.9081 - val_accuracy: 0.5600\n",
      "Epoch 175/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7186 - val_loss: 0.9241 - val_accuracy: 0.5664\n",
      "Epoch 176/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5564 - accuracy: 0.7180 - val_loss: 0.9339 - val_accuracy: 0.5629\n",
      "Epoch 177/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.7176 - val_loss: 0.9066 - val_accuracy: 0.5661\n",
      "Epoch 178/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7149 - val_loss: 0.9047 - val_accuracy: 0.5704\n",
      "Epoch 179/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7185 - val_loss: 0.9358 - val_accuracy: 0.5654\n",
      "Epoch 180/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5545 - accuracy: 0.7163 - val_loss: 0.9146 - val_accuracy: 0.5700\n",
      "Epoch 181/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7157 - val_loss: 0.8944 - val_accuracy: 0.5589\n",
      "Epoch 182/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.7192 - val_loss: 0.9386 - val_accuracy: 0.5621\n",
      "Epoch 183/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5559 - accuracy: 0.7203 - val_loss: 0.9243 - val_accuracy: 0.5718\n",
      "Epoch 184/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7140 - val_loss: 0.9161 - val_accuracy: 0.5736\n",
      "Epoch 185/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7177 - val_loss: 0.9006 - val_accuracy: 0.5686\n",
      "Epoch 186/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5542 - accuracy: 0.7143 - val_loss: 0.9164 - val_accuracy: 0.5661\n",
      "Epoch 187/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5542 - accuracy: 0.7165 - val_loss: 0.9248 - val_accuracy: 0.5664\n",
      "Epoch 188/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7140 - val_loss: 0.9068 - val_accuracy: 0.5639\n",
      "Epoch 189/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.7138 - val_loss: 0.9571 - val_accuracy: 0.5693\n",
      "Epoch 190/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7182 - val_loss: 0.8812 - val_accuracy: 0.5639\n",
      "Epoch 191/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.7152 - val_loss: 0.9303 - val_accuracy: 0.5675\n",
      "Epoch 192/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7110 - val_loss: 0.9062 - val_accuracy: 0.5671\n",
      "Epoch 193/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7159 - val_loss: 0.9682 - val_accuracy: 0.5714\n",
      "Epoch 194/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5534 - accuracy: 0.7156 - val_loss: 0.9137 - val_accuracy: 0.5729\n",
      "Epoch 195/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7177 - val_loss: 0.9193 - val_accuracy: 0.5632\n",
      "Epoch 196/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7150 - val_loss: 0.9611 - val_accuracy: 0.5657\n",
      "Epoch 197/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5509 - accuracy: 0.7166 - val_loss: 0.9151 - val_accuracy: 0.5639\n",
      "Epoch 198/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7189 - val_loss: 0.9339 - val_accuracy: 0.5689\n",
      "Epoch 199/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.7167 - val_loss: 0.9241 - val_accuracy: 0.5668\n",
      "Epoch 200/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5579 - accuracy: 0.7125 - val_loss: 0.9439 - val_accuracy: 0.5650\n",
      "Epoch 201/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7170 - val_loss: 0.9407 - val_accuracy: 0.5682\n",
      "Epoch 202/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5560 - accuracy: 0.7160 - val_loss: 0.9448 - val_accuracy: 0.5596\n",
      "Epoch 203/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5535 - accuracy: 0.7178 - val_loss: 0.9189 - val_accuracy: 0.5732\n",
      "Epoch 204/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7192 - val_loss: 0.9121 - val_accuracy: 0.5668\n",
      "Epoch 205/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.7182 - val_loss: 0.9168 - val_accuracy: 0.5721\n",
      "Epoch 206/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.7182 - val_loss: 0.9279 - val_accuracy: 0.5739\n",
      "Epoch 207/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5532 - accuracy: 0.7171 - val_loss: 0.9176 - val_accuracy: 0.5646\n",
      "Epoch 208/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5580 - accuracy: 0.7147 - val_loss: 0.8969 - val_accuracy: 0.5682\n",
      "Epoch 209/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7157 - val_loss: 0.9203 - val_accuracy: 0.5646\n",
      "Epoch 210/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5526 - accuracy: 0.7189 - val_loss: 0.9071 - val_accuracy: 0.5768\n",
      "Epoch 211/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7179 - val_loss: 0.9431 - val_accuracy: 0.5711\n",
      "Epoch 212/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7212 - val_loss: 0.9450 - val_accuracy: 0.5657\n",
      "Epoch 213/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7200 - val_loss: 0.9631 - val_accuracy: 0.5650\n",
      "Epoch 214/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7218 - val_loss: 0.9839 - val_accuracy: 0.5689\n",
      "Epoch 215/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7149 - val_loss: 0.9187 - val_accuracy: 0.5764\n",
      "Epoch 216/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5564 - accuracy: 0.7164 - val_loss: 0.9295 - val_accuracy: 0.5636\n",
      "Epoch 217/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.7197 - val_loss: 0.9281 - val_accuracy: 0.5679\n",
      "Epoch 218/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7159 - val_loss: 0.9524 - val_accuracy: 0.5629\n",
      "Epoch 219/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7100 - val_loss: 0.9208 - val_accuracy: 0.5736\n",
      "Epoch 220/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7137 - val_loss: 0.8873 - val_accuracy: 0.5679\n",
      "Epoch 221/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5573 - accuracy: 0.7150 - val_loss: 0.9193 - val_accuracy: 0.5696\n",
      "Epoch 222/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5596 - accuracy: 0.7160 - val_loss: 0.9027 - val_accuracy: 0.5682\n",
      "Epoch 223/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7178 - val_loss: 0.9748 - val_accuracy: 0.5696\n",
      "Epoch 224/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7174 - val_loss: 0.9231 - val_accuracy: 0.5661\n",
      "Epoch 225/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5534 - accuracy: 0.7149 - val_loss: 0.9416 - val_accuracy: 0.5679\n",
      "Epoch 226/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5513 - accuracy: 0.7179 - val_loss: 0.9959 - val_accuracy: 0.5700\n",
      "Epoch 227/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5509 - accuracy: 0.7217 - val_loss: 0.9482 - val_accuracy: 0.5671\n",
      "Epoch 228/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5504 - accuracy: 0.7216 - val_loss: 0.9314 - val_accuracy: 0.5686\n",
      "Epoch 229/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7215 - val_loss: 0.9325 - val_accuracy: 0.5621\n",
      "Epoch 230/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5495 - accuracy: 0.7232 - val_loss: 0.9812 - val_accuracy: 0.5721\n",
      "Epoch 231/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5482 - accuracy: 0.7244 - val_loss: 0.9724 - val_accuracy: 0.5696\n",
      "Epoch 232/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7138 - val_loss: 0.9800 - val_accuracy: 0.5693\n",
      "Epoch 233/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5546 - accuracy: 0.7164 - val_loss: 0.9733 - val_accuracy: 0.5696\n",
      "Epoch 234/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7193 - val_loss: 0.9081 - val_accuracy: 0.5654\n",
      "Epoch 235/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7185 - val_loss: 0.9851 - val_accuracy: 0.5736\n",
      "Epoch 236/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.7172 - val_loss: 0.9427 - val_accuracy: 0.5746\n",
      "Epoch 237/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7209 - val_loss: 0.9333 - val_accuracy: 0.5754\n",
      "Epoch 238/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7199 - val_loss: 0.9464 - val_accuracy: 0.5750\n",
      "Epoch 239/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7139 - val_loss: 0.9346 - val_accuracy: 0.5689\n",
      "Epoch 240/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7179 - val_loss: 1.0130 - val_accuracy: 0.5664\n",
      "Epoch 241/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7166 - val_loss: 0.9959 - val_accuracy: 0.5682\n",
      "Epoch 242/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7163 - val_loss: 0.9468 - val_accuracy: 0.5643\n",
      "Epoch 243/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7162 - val_loss: 0.9685 - val_accuracy: 0.5725\n",
      "Epoch 244/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7219 - val_loss: 0.9760 - val_accuracy: 0.5714\n",
      "Epoch 245/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7228 - val_loss: 0.9745 - val_accuracy: 0.5650\n",
      "Epoch 246/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.7198 - val_loss: 0.9804 - val_accuracy: 0.5725\n",
      "Epoch 247/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7185 - val_loss: 0.9383 - val_accuracy: 0.5746\n",
      "Epoch 248/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5549 - accuracy: 0.7164 - val_loss: 0.9516 - val_accuracy: 0.5675\n",
      "Epoch 249/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7157 - val_loss: 0.9523 - val_accuracy: 0.5696\n",
      "Epoch 250/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.7144 - val_loss: 1.0139 - val_accuracy: 0.5682\n",
      "Epoch 251/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7194 - val_loss: 0.9310 - val_accuracy: 0.5732\n",
      "Epoch 252/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7180 - val_loss: 0.9422 - val_accuracy: 0.5643\n",
      "Epoch 253/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7184 - val_loss: 0.9973 - val_accuracy: 0.5700\n",
      "Epoch 254/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7172 - val_loss: 0.9430 - val_accuracy: 0.5675\n",
      "Epoch 255/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7227 - val_loss: 0.9851 - val_accuracy: 0.5679\n",
      "Epoch 256/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7237 - val_loss: 0.9888 - val_accuracy: 0.5721\n",
      "Epoch 257/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5499 - accuracy: 0.7202 - val_loss: 0.9618 - val_accuracy: 0.5711\n",
      "Epoch 258/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7189 - val_loss: 0.9544 - val_accuracy: 0.5757\n",
      "Epoch 259/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7191 - val_loss: 0.9450 - val_accuracy: 0.5696\n",
      "Epoch 260/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7172 - val_loss: 1.0091 - val_accuracy: 0.5721\n",
      "Epoch 261/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5550 - accuracy: 0.7144 - val_loss: 0.9768 - val_accuracy: 0.5796\n",
      "Epoch 262/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5512 - accuracy: 0.7149 - val_loss: 0.9181 - val_accuracy: 0.5768\n",
      "Epoch 263/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.7189 - val_loss: 0.9912 - val_accuracy: 0.5629\n",
      "Epoch 264/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7109 - val_loss: 0.9821 - val_accuracy: 0.5696\n",
      "Epoch 265/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5582 - accuracy: 0.7114 - val_loss: 0.9561 - val_accuracy: 0.5693\n",
      "Epoch 266/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5562 - accuracy: 0.7147 - val_loss: 0.9389 - val_accuracy: 0.5711\n",
      "Epoch 267/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7161 - val_loss: 0.9422 - val_accuracy: 0.5761\n",
      "Epoch 268/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7189 - val_loss: 0.9546 - val_accuracy: 0.5729\n",
      "Epoch 269/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7220 - val_loss: 1.0024 - val_accuracy: 0.5739\n",
      "Epoch 270/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7164 - val_loss: 0.9793 - val_accuracy: 0.5671\n",
      "Epoch 271/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7198 - val_loss: 0.9605 - val_accuracy: 0.5679\n",
      "Epoch 272/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7176 - val_loss: 0.9661 - val_accuracy: 0.5668\n",
      "Epoch 273/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7222 - val_loss: 0.9846 - val_accuracy: 0.5682\n",
      "Epoch 274/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7188 - val_loss: 1.0023 - val_accuracy: 0.5757\n",
      "Epoch 275/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7211 - val_loss: 0.9964 - val_accuracy: 0.5686\n",
      "Epoch 276/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7198 - val_loss: 0.9310 - val_accuracy: 0.5671\n",
      "Epoch 277/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7198 - val_loss: 0.9623 - val_accuracy: 0.5721\n",
      "Epoch 278/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7239 - val_loss: 0.9286 - val_accuracy: 0.5679\n",
      "Epoch 279/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.7199 - val_loss: 0.9683 - val_accuracy: 0.5771\n",
      "Epoch 280/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5470 - accuracy: 0.7191 - val_loss: 1.0022 - val_accuracy: 0.5718\n",
      "Epoch 281/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7206 - val_loss: 0.9423 - val_accuracy: 0.5736\n",
      "Epoch 282/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5526 - accuracy: 0.7164 - val_loss: 0.9650 - val_accuracy: 0.5739\n",
      "Epoch 283/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7182 - val_loss: 0.9515 - val_accuracy: 0.5679\n",
      "Epoch 284/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7210 - val_loss: 1.0039 - val_accuracy: 0.5696\n",
      "Epoch 285/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7212 - val_loss: 1.0544 - val_accuracy: 0.5714\n",
      "Epoch 286/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5455 - accuracy: 0.7235 - val_loss: 0.9810 - val_accuracy: 0.5729\n",
      "Epoch 287/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7168 - val_loss: 0.9592 - val_accuracy: 0.5729\n",
      "Epoch 288/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5530 - accuracy: 0.7168 - val_loss: 0.9629 - val_accuracy: 0.5689\n",
      "Epoch 289/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5549 - accuracy: 0.7164 - val_loss: 0.9514 - val_accuracy: 0.5771\n",
      "Epoch 290/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7158 - val_loss: 0.9350 - val_accuracy: 0.5768\n",
      "Epoch 291/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7151 - val_loss: 0.9831 - val_accuracy: 0.5686\n",
      "Epoch 292/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7221 - val_loss: 0.9527 - val_accuracy: 0.5729\n",
      "Epoch 293/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7231 - val_loss: 1.0084 - val_accuracy: 0.5704\n",
      "Epoch 294/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5438 - accuracy: 0.7231 - val_loss: 0.9485 - val_accuracy: 0.5729\n",
      "Epoch 295/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7206 - val_loss: 1.0179 - val_accuracy: 0.5721\n",
      "Epoch 296/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5521 - accuracy: 0.7179 - val_loss: 0.9638 - val_accuracy: 0.5668\n",
      "Epoch 297/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5492 - accuracy: 0.7196 - val_loss: 0.9646 - val_accuracy: 0.5657\n",
      "Epoch 298/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7194 - val_loss: 0.9381 - val_accuracy: 0.5636\n",
      "Epoch 299/300\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7177 - val_loss: 0.9699 - val_accuracy: 0.5686\n",
      "Epoch 300/300\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.5469 - accuracy: 0.7202 - val_loss: 0.9603 - val_accuracy: 0.5604\n"
     ]
    }
   ],
   "source": [
    "#creating unique name for tensorboard directory\n",
    "log_dir = \"logs/NN/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#Tensforboard callback function\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "struct = [20,10,30]\n",
    "dim = X_train.shape[1]\n",
    "model = NN_TF_model(structure = struct, ipt_dim = dim)\n",
    "history = model.fit(X_train,\n",
    "                  y_train,\n",
    "                  validation_split = 0.2,\n",
    "                  epochs=300,\n",
    "                  batch_size=100,\n",
    "                  shuffle=True,\n",
    "                  callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93d452b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.test_on_batch(X_test, y_test)\n",
    "model.metrics_names\n",
    "print(history.history.keys())\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'b.', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'g', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "# plt.plot(epochs, loss, 'b.', label='Training loss')\n",
    "# plt.plot(epochs, val_loss, 'g', label='Validation loss')\n",
    "# plt.title('Training and validation loss')\n",
    "# plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c54765a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = metrics.Accuracy()\n",
    "mc = metrics.CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d7c73df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 0s 620us/step\n"
     ]
    }
   ],
   "source": [
    "y_hat=model.predict(X_train)>0.5\n",
    "y_hat=np.squeeze(y_hat)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3a998b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "away win rate =  0.4419518468243195\n",
      "Train data accuracy 0.6930771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[5587, 2072],\n",
       "       [2224, 4114]], dtype=int32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.update_state(y_train, y_hat)\n",
    "mc.update_state(y_train, y_hat)\n",
    "print('away win rate = ', sum(y_hat)/len(y_hat))\n",
    "print('Train data accuracy',m.result().numpy())\n",
    "# print('Train data categorical accuracy',mc.result().numpy())\n",
    "tf.math.confusion_matrix(y_train, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fffbd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 0s 587us/step\n"
     ]
    }
   ],
   "source": [
    "y_hat=model.predict(X_test)>0.5\n",
    "y_hat=np.squeeze(y_hat)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d63e89aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "away win rate =  0.44657142857142856\n",
      "Test data accuracy 0.6701149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[1188,  727],\n",
       "       [ 749,  836]], dtype=int32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.update_state(y_test, y_hat)\n",
    "print('away win rate = ',sum(y_hat)/len(y_hat))\n",
    "print('Test data accuracy',m.result().numpy())\n",
    "tf.math.confusion_matrix(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02122db1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
